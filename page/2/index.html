<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>沧海一粟</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="沧海一粟">
<meta property="og:url" content="https://whales2018.github.io/page/2/index.html">
<meta property="og:site_name" content="沧海一粟">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="沧海一粟">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">沧海一粟</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://whales2018.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-http-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/20/http-1/" class="article-date">
  <time datetime="2018-07-20T03:21:11.000Z" itemprop="datePublished">2018-07-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/《HTTP权威指南》阅读笔记/">《HTTP权威指南》阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/20/http-1/">《HTTP权威指南》阅读笔记一</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-常见概念"><a href="#1-常见概念" class="headerlink" title="1. 常见概念"></a>1. 常见概念</h1><ol>
<li><p>MIME：Multipurpose Internet Mail Extension，电子邮件系统和HTTP用于描述标记多媒体内容</p>
</li>
<li><p>URI：统一资源标识符，可以有URL和URN两种形式</p>
</li>
<li><p>URL：协议+服务器地址+资源路径</p>
</li>
<li><p>事务：通过HTTP报文格式化数据块完成一次请求和响应</p>
</li>
</ol>
<h1 id="2-URL与资源"><a href="#2-URL与资源" class="headerlink" title="2. URL与资源"></a>2. URL与资源</h1><ol>
<li><p>大多数URL方案的语法建立在<scheme>://<user>:<password>@<host>:<port>/<path></path>;<params>?<query>#<frag></frag></query></params></port></host></password></user></scheme></p>
</li>
<li><p>设计URL使其可以通过任意因特网协议安全传输是很重要的，有些协议如SMTP的传输方法只能使用相对较小，通用的安全字母表中的字符</p>
</li>
<li><p>URL中包含如中文等非安全字母表二进制数据或字符时，则需要进行转义</p>
</li>
<li><p>转义：百分号+字符编码的十六进制数</p>
</li>
</ol>
<h1 id="3-HTTP报文"><a href="#3-HTTP报文" class="headerlink" title="3. HTTP报文"></a>3. HTTP报文</h1><ol>
<li>组成：对报文进行描述的起始行start line \r\n作为行结束，包含属性的首部块header，包含数据的body</li>
</ol>
<h2 id="常见HTTP方法"><a href="#常见HTTP方法" class="headerlink" title="常见HTTP方法"></a>常见HTTP方法</h2><ol>
<li>GET，HEAD，POST，PUT，DELETE，TRACE(对可能经过代理服务器传送的报文进行追踪，服务响应会带上实际收到的请求原文)，OPTIONS(决定可以在服务器上执行哪些方法)</li>
</ol>
<h2 id="已定义状态码"><a href="#已定义状态码" class="headerlink" title="已定义状态码"></a>已定义状态码</h2><ol>
<li>100-101：信息提示</li>
<li>200-206：成功</li>
<li>300-305：重定向</li>
<li>400-415：客户端错误</li>
<li>500-505：服务端错误</li>
</ol>
<h1 id="4-连接管理"><a href="#4-连接管理" class="headerlink" title="4. 连接管理"></a>4. 连接管理</h1><ol>
<li>连接过程：解析主机名，dns查询ip，获取端口号，发起连接，发送请求报文，返回响应报文，关闭连接</li>
<li>HTTP事务时延：DNS查询，连接，请求，处理，响应，关闭</li>
<li>性能聚焦区域：TCP连接，TCP慢启动拥塞控制，数据聚集的Nagle算法+TCP延迟确认，TIME_WAIT时延和端口耗尽</li>
<li>并行连接：由客户端的网络带宽限制并行连接数</li>
<li>持久连接：HTTP/1.1及HTTP/1.0的增强版本 允许设备在事务处理结束时将连接保持打开状态，省去建立连接和慢启动的阶段，1.0可以通过Connection：keep-alive</li>
<li>管道化连接：HTTP/1.1允许在持久连接上使用请求管道，响应到达前将请求放入队列，不能传送非幂等请求如POST</li>
</ol>
<h1 id="5-Web服务器"><a href="#5-Web服务器" class="headerlink" title="5. Web服务器"></a>5. Web服务器</h1><ol>
<li>重定向使用场景：永久删除或临时删除的资源，负载均衡，服务器关联，规范目录名称</li>
<li>对非持久连接，发送完响应关闭服务端连接；对持久连接，需要正确计算content-length首部</li>
</ol>
<h1 id="6-代理"><a href="#6-代理" class="headerlink" title="6. 代理"></a>6. 代理</h1><ol>
<li>代理可以监视流量并对其进行修改</li>
<li>应用场景：安全防火墙，Web缓存，反向代理，内容路由器，转码，匿名</li>
<li>via： 列出了与报文途径的每个中间节点</li>
</ol>
<h1 id="7-缓存"><a href="#7-缓存" class="headerlink" title="7. 缓存"></a>7. 缓存</h1><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><ol>
<li>冗余的数据传输：服务器多次传输同一份文档，增大负担，消耗带宽</li>
<li>带宽瓶颈：客户端会以路径上最慢的网速访问服务器，如果客户端能在局域网获取一份副本，将大大提升性能</li>
<li>瞬间拥塞：使web服务器过载</li>
<li>距离时延</li>
</ol>
<h2 id="缓存再验证"><a href="#缓存再验证" class="headerlink" title="缓存再验证"></a>缓存再验证</h2><ol>
<li>大部分缓存只有在客户端发起请求，且副本时间需要再次检测才会进行再验证</li>
<li>向原始服务器发送小请求，如果返回304，则缓存继续有效</li>
<li>首部：if-modified-since，只有在缓存了对象的副本后又对其进行修改，才发送此对象</li>
<li>商业代理缓存会在via首部附加额外信息以描述命中情况</li>
</ol>
<h2 id="HTTP缓存体系"><a href="#HTTP缓存体系" class="headerlink" title="HTTP缓存体系"></a>HTTP缓存体系</h2><ol>
<li>缓存存储策略：决定http响应内容是否可缓存到客户端，Cache-Control</li>
<li>缓存过期策略：决定客户端是否可以直接使用缓存数据，Expires</li>
<li>缓存对比策略：将缓存在客户端的数据标识发往服务端，服务端会查看if-modified-since等请求头，对比判断标识是否有效，如果有效则返回304</li>
</ol>
<h2 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h2><ol>
<li><a href="https://imweb.io/topic/5795dcb6fb312541492eda8c" target="_blank" rel="noopener">HTTP缓存控制小结</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/24467558" target="_blank" rel="noopener">彻底弄懂 Http 缓存机制</a></li>
</ol>
<h1 id="8-网关，隧道及中继"><a href="#8-网关，隧道及中继" class="headerlink" title="8. 网关，隧道及中继"></a>8. 网关，隧道及中继</h1><h2 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h2><p>如应用程序服务器，早期的CGI通用网关接口</p>
<h2 id="隧道"><a href="#隧道" class="headerlink" title="隧道"></a>隧道</h2><ol>
<li>web隧道允许用户通过http连接发送非http流量</li>
<li>使用http方法CONNECT建立http隧道</li>
<li>SSL隧道：最初的web隧道是为了通过防火墙传输SSL流量。发送CONNECT请求，返回认证请求，发送带有认证信息CONNECT请求，建立连接</li>
</ol>
<h2 id="中继"><a href="#中继" class="headerlink" title="中继"></a>中继</h2><ol>
<li>盲转发</li>
<li>无法处理Connection：keep-alive</li>
</ol>
<h1 id="9-爬虫"><a href="#9-爬虫" class="headerlink" title="9. 爬虫"></a>9. 爬虫</h1><ol>
<li>链接提取及相对链接的标准化</li>
<li>避免环路的出现</li>
<li>广度优先</li>
<li>节流</li>
<li>内容指纹</li>
</ol>
<h1 id="10-客户端识别与cookie机制"><a href="#10-客户端识别与cookie机制" class="headerlink" title="10. 客户端识别与cookie机制"></a>10. 客户端识别与cookie机制</h1><h2 id="用户识别机制"><a href="#用户识别机制" class="headerlink" title="用户识别机制"></a>用户识别机制</h2><ol>
<li>承载用户信息的HTTP首部：user-agent，cookie，referer，x-forward–for等</li>
<li>客户端IP地址：并不能精确识别客户</li>
<li>用户登录：通过www-authenticate，authorization首部</li>
<li>cookie</li>
</ol>
<h1 id="11-基本认证机制"><a href="#11-基本认证机制" class="headerlink" title="11. 基本认证机制"></a>11. 基本认证机制</h1><ol>
<li>实际使用并不安全，用户名和密码都是以明文形式传送，安全使用的唯一方式就是结合SSL</li>
</ol>
<h1 id="12-摘要认证"><a href="#12-摘要认证" class="headerlink" title="12. 摘要认证"></a>12. 摘要认证</h1><ol>
<li>用摘要保护密码，不通过网络发送密码</li>
<li>单向摘要，MD5输出的128位摘要被写成32个16进制字符</li>
<li>用随机数防止重放攻击，服务器质询时返回给客户端一个随机数，客户端在计算摘要之前要加上这个随机数</li>
</ol>
<h1 id="13-安全HTTP"><a href="#13-安全HTTP" class="headerlink" title="13. 安全HTTP"></a>13. 安全HTTP</h1><ol>
<li>对称秘钥加密：编码和解码使用相同的秘钥，流行算法：DES，RC2，RC4</li>
<li>公开秘钥加密：使用非对称秘钥，只有接收端可以用私钥解密，RSA算法</li>
<li>公开秘钥加密算法的计算可能会很慢，对称加密更快</li>
<li>两个节点间通过公开秘钥加密建立安全通信，再用安全通道产生发送临时随机对称秘钥</li>
<li>数字签名：附加在报文上的特殊加密校验码，可以证明是作者编写了这条报文，防止报文被篡改</li>
<li>数字证书：对象，过期时间，发布者，公钥，数字签名等，常见标准格式X.509 v3</li>
<li>浏览器收到服务器证书后，会对签名颁发机构进行检查</li>
<li>SSL握手：交换协议版本号，选择一个两端都了解的密码，对两端的身份进行认证，生成临时会话秘钥。</li>
<li>服务器可以要求客户端使用客户端证书，常见于组织机构内网</li>
<li>站点证书有效性：日期检测，签名颁发者可信度检测，签名检测，站点身份检测检查证书域名与访问站点域名是否一致</li>
<li>OpenSSL：SSL和TLS常见的开源实现，创建SSL本地上下文，建立443TCP连接，将SSL层附加到TCP连接，SSL握手</li>
<li>HTTPS SSL隧道协议：http通过CONNECT方法告诉代理，建立一条直接到服务端的连接，以隧道协议传输数据</li>
</ol>
<h1 id="14-实体和编码"><a href="#14-实体和编码" class="headerlink" title="14. 实体和编码"></a>14. 实体和编码</h1><ol>
<li>content-length：检测报文截尾，这对缓存服务器尤其重要；对于持久连接，客户端需要直到报文在哪里结束</li>
<li>内容编码：如果主体进行编码，content-length说明的就是编码后的长度；编码后，增加content-encoding首部用户客户端解码；客户端通过accept-encoding告知服务端可以接受的编码方式</li>
<li>实体摘要：发送方在生成初始主体时生成一个数据校验和，这样接收方就可以通过检查这个校验和捕获所有意外，相关首部content-md5</li>
<li>传输编码：改变报文数据在网络中的传输方式，解决可靠传输存在的问题：未知尺寸，用传输编码发送数据，用特别的结束脚注表明数据结束；安全性（被SSL取代），扰乱报文内容</li>
<li>Transfer-Encoding：传输编码类型，TE：告诉服务器可以使用哪些传输编码扩展</li>
<li>分块编码：把报文分割为若干个小块紧挨着发送。非持久连接，客户端读取直到服务端关闭连接。持久连接，说明每块大小，最后用0块作为主体结束的信号</li>
<li>传输编码规则：传输编码集合中要包含分块；必须最后一个作用于报文主体；不能多次作用到一个报文主体上；</li>
<li>范围请求：允许客户端只请求文档的一部分，在点对点文件共享客户端应用广泛</li>
<li>差异编码：客户端可以使用A-IM首部说明可以接受的实例操控类型，Delta-base用于计算差异的基线文档Etag，支持差异编码的服务器必须保持页面随时间变化的多个版本</li>
</ol>
<h1 id="15-国际化"><a href="#15-国际化" class="headerlink" title="15. 国际化"></a>15. 国际化</h1><ol>
<li>charset参数和content-language：告知客户端文档的字母表和语言</li>
<li>accept-language和accept-charset：告知服务端支持的字母表和语言及其优先顺序</li>
</ol>
<h1 id="16-内容协商与转码"><a href="#16-内容协商与转码" class="headerlink" title="16. 内容协商与转码"></a>16. 内容协商与转码</h1><ol>
<li>Vary：响应首部列出客户端请求首部，服务端可用这些首部选择文档</li>
<li>转码：格式转换，信息综合，内容注入</li>
</ol>
<h1 id="17-内容发布与分发"><a href="#17-内容发布与分发" class="headerlink" title="17. 内容发布与分发"></a>17. 内容发布与分发</h1><ol>
<li>CDN：内容分发网络，节点可以是web服务器，反向代理，或缓存</li>
</ol>
<h1 id="18-重定向与负载均衡"><a href="#18-重定向与负载均衡" class="headerlink" title="18. 重定向与负载均衡"></a>18. 重定向与负载均衡</h1><ol>
<li>HTTP重定向：增加时延</li>
<li>DNS重定向：返回多个ip选中的ip，缺点时DNS会缓存</li>
<li>任播寻址：地理上分散的web服务器拥有相同的ip地址，将地址广告给骨干网路由，则客户端的请求将通过最短路径路由给最近的服务器</li>
<li>IP MAC转发：交换机将分组转发到指定MAC地址</li>
<li>IP地址转发：修改目的IP地址，即NAT网络地址交换</li>
<li>代理自动配置协议PAC：配置url使用代理</li>
</ol>
<h1 id="19-日志记录"><a href="#19-日志记录" class="headerlink" title="19. 日志记录"></a>19. 日志记录</h1><ol>
<li>常用日志格式：参考nginx access.log</li>
<li>对重要的页面进行缓存清除</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/07/20/http-1/" data-id="cjsvjedgm000tlwt91i2rcdy3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-amqp" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/17/amqp/" class="article-date">
  <time datetime="2018-07-17T14:44:38.000Z" itemprop="datePublished">2018-07-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python源码学习/">Python源码学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/17/amqp/">Python amqp源码学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p>python amqp 包的代码量小，有助于我们学习AMQP，首先我们了解一下包的目录结构。大致阅读整体代码后，我们能够了解到整体的分层设计大致如图。之后我们再深入每一层的代码实现，由底至上，学习相关的知识点。阅读完整个的源码后，我们再尝试用golang重新撸一遍实现。</p>
<p><img src="https://whales2018.github.io/pic/pic3.png" alt="amqp包目录结构"></p>
<p><img src="https://whales2018.github.io/pic/pic2.png" alt="amqp源码分层"></p>
<h3 id="Transport"><a href="#Transport" class="headerlink" title="Transport"></a>Transport</h3><p>这一层主要是基于TCP连接，实现带缓冲区套接字字节流的读写，协议数据报的读写</p>
<p><img src="https://whales2018.github.io/pic/pic1.png" alt="transport"></p>
<ul>
<li><p>协议无关性：socket.getaddrinfo 将返回目标地址支持的套接字信息并返回已填入相关信息的网际套接字地址结构sa，可以直接conenct。无需考虑IPv4还是IPv6</p>
</li>
<li><p>设置描述符cloexec，子进程fork之后调用exec函数成功后，会自动关闭文件描述符，避免父进程退出重启后因为端口占用无法重启：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def set_cloexec(fd, cloexec):</span><br><span class="line">    try:</span><br><span class="line">        FD_CLOEXEC = fcntl.FD_CLOEXEC</span><br><span class="line">    except AttributeError:</span><br><span class="line">        raise NotImplementedError(</span><br><span class="line">            &apos;close-on-exec flag not supported on this platform&apos;,</span><br><span class="line">        )</span><br><span class="line">    flags = fcntl.fcntl(fd, fcntl.F_GETFD)</span><br><span class="line">    if cloexec:</span><br><span class="line">        flags |= FD_CLOEXEC</span><br><span class="line">    else:</span><br><span class="line">        flags &amp;= ~FD_CLOEXEC</span><br><span class="line">    return fcntl.fcntl(fd, fcntl.F_SETFD, flags)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>套接字选项设置，详情可以参考《UNIX网络编程卷1》第7章</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)</span><br><span class="line">self.sock.setsockopt(SOL_TCP, socket.TCP_NODELAY, 1)</span><br></pre></td></tr></table></figure>
</li>
<li><p>套接字读写，TCPTransport和SSLTransport分别实现了抽象类的套接字读写方法。SSLTransport使用ssl库包裹了当前套接字并使用ssl的读写方法。读数据时，可能出现的异常</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">errno.ENOENT：recv收到对端发送的RST产生的错误</span><br><span class="line">errno.EAGAIN：如果设置成非阻塞读，没有数据可读时，返回该错误</span><br><span class="line">errno.EINTR：慢系统调用中断，常见于子进程终止时传递信号给父进程</span><br></pre></td></tr></table></figure>
<ul>
<li>协议数据报读写，从读取的方法，我们可以得到协议数据报的格式 帧类型1字节 + 2字节信道id + 4字节payload size + size字节payload + 1字节结束标志<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def read_frame(self, unpack=unpack):</span><br><span class="line">    ...</span><br><span class="line">    frame_header = read(7, True)</span><br><span class="line">    read_frame_buffer += frame_header</span><br><span class="line">    frame_type, channel, size = unpack(&apos;&gt;BHI&apos;, frame_header)</span><br><span class="line">    payload = read(size)</span><br><span class="line">    read_frame_buffer += payload</span><br><span class="line">    ch = ord(read(1))</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">def write_frame(self, frame_type, channel, payload)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="数据协议层"><a href="#数据协议层" class="headerlink" title="数据协议层"></a>数据协议层</h3><p>这一层主要提供了字节流与上层数据类型的转换工具AMQPReader/AMQPWriter，不同帧类型的数据报的组装和读取解析工具MethodWriter/MethodReader。我们先研究一个具体使用的场景如声明exchange_declare。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">class Channel(AbstractChannel):</span><br><span class="line">    def exchange_declare(self, exchange, type, passive=False, durable=False,</span><br><span class="line">                         auto_delete=True, nowait=False, arguments=None):</span><br><span class="line">                arguments = &#123;&#125; if arguments is None else arguments</span><br><span class="line">        args = AMQPWriter()</span><br><span class="line">        args.write_short(0)</span><br><span class="line">        args.write_shortstr(exchange)</span><br><span class="line">        args.write_shortstr(type)</span><br><span class="line">        args.write_bit(passive)</span><br><span class="line">        args.write_bit(durable)</span><br><span class="line">        args.write_bit(auto_delete)</span><br><span class="line">        args.write_bit(False)  # internal: deprecated</span><br><span class="line">        args.write_bit(nowait)</span><br><span class="line">        args.write_table(arguments)</span><br><span class="line">        self._send_method((40, 10), args)</span><br><span class="line"></span><br><span class="line">        if auto_delete:</span><br><span class="line">            warn(VDeprecationWarning(EXCHANGE_AUTODELETE_DEPRECATED))</span><br><span class="line"></span><br><span class="line">        if not nowait:</span><br><span class="line">            return self.wait(allowed_methods=[</span><br><span class="line">                (40, 11),  # Channel.exchange_declare_ok</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure>
<p>通过AMQPWriter，将exchange_declare的参数序列化为字节流args，通过查看_send_method可以知道最后由MethodWriter.write_method执行组装发送，这里的write_frame则由底层的transport提供</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class MethodWriter(object):</span><br><span class="line">    def write_method(self, channel, method_sig, args, content=None):</span><br><span class="line">        write_frame = self.dest.write_frame</span><br><span class="line">        payload = pack(&apos;&gt;HH&apos;, method_sig[0], method_sig[1]) + args</span><br><span class="line">        ...</span><br><span class="line">        write_frame(1, channel, payload)</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>至此我们已经初步了解了从上层抽象的操作接口到底层字节流的转换进行通信的过程。而上述只是一个基本的包含参数的操作，对于带有消息内容的发布与接收操作，则增加两种类型：消息头部和消息实体。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class MethodWriter(object):</span><br><span class="line">    def write_method(self, channel, method_sig, args, content=None):</span><br><span class="line">        ...</span><br><span class="line">        if content:</span><br><span class="line">            body = content.body</span><br><span class="line">            if isinstance(body, string):</span><br><span class="line">                coding = content.properties.get(&apos;content_encoding&apos;, None)</span><br><span class="line">                if coding is None:</span><br><span class="line">                    coding = content.properties[&apos;content_encoding&apos;] = &apos;UTF-8&apos;</span><br><span class="line"></span><br><span class="line">                body = body.encode(coding)</span><br><span class="line">            properties = content._serialize_properties()</span><br><span class="line">        ...</span><br><span class="line">        if content:</span><br><span class="line">            payload = pack(&apos;&gt;HHQ&apos;, method_sig[0], 0, len(body)) + properties</span><br><span class="line"></span><br><span class="line">            write_frame(2, channel, payload)</span><br><span class="line"></span><br><span class="line">            chunk_size = self.frame_max - 8</span><br><span class="line">            for i in range(0, len(body), chunk_size):</span><br><span class="line">                write_frame(3, channel, body[i:i + chunk_size])</span><br><span class="line">        self.bytes_sent += 1</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">class Message(GenericContent):</span><br><span class="line">        PROPERTIES = [</span><br><span class="line">        (&apos;content_type&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;content_encoding&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;application_headers&apos;, &apos;table&apos;),</span><br><span class="line">        (&apos;delivery_mode&apos;, &apos;octet&apos;),</span><br><span class="line">        (&apos;priority&apos;, &apos;octet&apos;),</span><br><span class="line">        (&apos;correlation_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;reply_to&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;expiration&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;message_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;timestamp&apos;, &apos;timestamp&apos;),</span><br><span class="line">        (&apos;type&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;user_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;app_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;cluster_id&apos;, &apos;shortstr&apos;)</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>
<p>还是同一个方法，这次我们关注frame_type为2的消息头部，从图可以看出这次需要得到两个关键信息就是消息实体的长度和序列化后的消息头的属性，消息实体的长度计算的是编码后的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">class GenericContent(object):</span><br><span class="line">    def _load_properties(self, raw_bytes):</span><br><span class="line">        r = AMQPReader(raw_bytes)</span><br><span class="line">        flags = []</span><br><span class="line">        while 1:</span><br><span class="line">            flag_bits = r.read_short()</span><br><span class="line">            flags.append(flag_bits)</span><br><span class="line">            if flag_bits &amp; 1 == 0:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">        shift = 0</span><br><span class="line">        d = &#123;&#125;</span><br><span class="line">        for key, proptype in self.PROPERTIES:</span><br><span class="line">            if shift == 0:</span><br><span class="line">                if not flags:</span><br><span class="line">                    break</span><br><span class="line">                flag_bits, flags = flags[0], flags[1:]</span><br><span class="line">                shift = 15</span><br><span class="line">            if flag_bits &amp; (1 &lt;&lt; shift):</span><br><span class="line">                d[key] = getattr(r, &apos;read_&apos; + proptype)()</span><br><span class="line">            shift -= 1</span><br><span class="line"></span><br><span class="line">        self.properties = d</span><br><span class="line">        </span><br><span class="line">    def _serialize_properties(self):</span><br><span class="line">        shift = 15</span><br><span class="line">        flag_bits = 0</span><br><span class="line">        flags = []</span><br><span class="line">        raw_bytes = AMQPWriter()</span><br><span class="line">        for key, proptype in self.PROPERTIES:</span><br><span class="line">            val = self.properties.get(key, None)</span><br><span class="line">            if val is not None:</span><br><span class="line">                if shift == 0:</span><br><span class="line">                    flags.append(flag_bits)</span><br><span class="line">                    flag_bits = 0</span><br><span class="line">                    shift = 15</span><br><span class="line"></span><br><span class="line">                flag_bits |= (1 &lt;&lt; shift)</span><br><span class="line">                if proptype != &apos;bit&apos;:</span><br><span class="line">                    getattr(raw_bytes, &apos;write_&apos; + proptype)(val)</span><br><span class="line"></span><br><span class="line">            shift -= 1</span><br><span class="line"></span><br><span class="line">        flags.append(flag_bits)</span><br><span class="line">        result = AMQPWriter()</span><br><span class="line">        for flag_bits in flags:</span><br><span class="line">            result.write_short(flag_bits)</span><br><span class="line">        result.write(raw_bytes.getvalue())</span><br><span class="line"></span><br><span class="line">        return result.getvalue()</span><br></pre></td></tr></table></figure>
<p>消息头属性的序列化，仍然是使用AMQPWriter来对值进行转换。需要考虑三个问题，一个是如何知道消息头的属性有多少个，二是属性在字节流的对应位置，三是确定每个属性在字节流对应位置的边界。<br>写的时候通过从高位到低位设置标记位，并依次根据属性值不同类型，写入属性值转换后的数据。<br>消息实体类型的处理相对简单，如果数据太大，则分片进行多次发送，需要考虑的是接收端同一个channel需要进行等待组装完整的数据接收</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">class _PartialMessage(object):</span><br><span class="line">    def add_header(self, payload):</span><br><span class="line">        ...</span><br><span class="line">    def add_payload(self, payload):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">class MethodReader(object):</span><br><span class="line">    def read_method(self):</span><br><span class="line">        self._next_method()</span><br><span class="line">        m = self._quick_get()</span><br><span class="line">        if isinstance(m, Exception):</span><br><span class="line">            raise m</span><br><span class="line">        if isinstance(m, tuple) and isinstance(m[1], AMQPError):</span><br><span class="line">            raise m[1]</span><br><span class="line">        return m</span><br><span class="line">        </span><br><span class="line">    def _next_method(self):</span><br><span class="line">        queue = self.queue</span><br><span class="line">        put = self._quick_put</span><br><span class="line">        read_frame = self.source.read_frame</span><br><span class="line">        while not queue:</span><br><span class="line">            try:</span><br><span class="line">                frame_type, channel, payload = read_frame()</span><br><span class="line">            except Exception as exc:</span><br><span class="line">                #</span><br><span class="line">                # Connection was closed?  Framing Error?</span><br><span class="line">                #</span><br><span class="line">                put(exc)</span><br><span class="line">                break</span><br><span class="line">    </span><br><span class="line">            self.bytes_recv += 1</span><br><span class="line">    </span><br><span class="line">            if frame_type not in (self.expected_types[channel], 8):</span><br><span class="line">                put((</span><br><span class="line">                    channel,</span><br><span class="line">                    UnexpectedFrame(</span><br><span class="line">                        &apos;Received frame &#123;0&#125; while expecting type: &#123;1&#125;&apos;.format(</span><br><span class="line">                            frame_type, self.expected_types[channel]))))</span><br><span class="line">            elif frame_type == 1:</span><br><span class="line">                self._process_method_frame(channel, payload)</span><br><span class="line">            elif frame_type == 2:</span><br><span class="line">                self._process_content_header(channel, payload)</span><br><span class="line">            elif frame_type == 3:</span><br><span class="line">                self._process_content_body(channel, payload)</span><br><span class="line">            elif frame_type == 8:</span><br><span class="line">                self._process_heartbeat(channel, payload)</span><br></pre></td></tr></table></figure>
<p>MethodReader提供了给上层消费者调用的read_method，内部维护一个临时队列，如果完整的数据每结束，则继续阻塞读取直到合并成完成的数据message对象，这一步临时存储和组装则由_PartialMessage完成</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/07/17/amqp/" data-id="cjsvjedgi000rlwt90dxgdyoo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-redis-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/redis-2/" class="article-date">
  <time datetime="2018-06-30T06:47:41.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/redis-2/">Redis文档阅读笔记二</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-Redis-Mass-Insertion"><a href="#1-Redis-Mass-Insertion" class="headerlink" title="1. Redis Mass Insertion"></a>1. Redis Mass Insertion</h1><ol>
<li>有时候需要将原先存有的大量数据迁移到新的redis实例,redis提供一些方案可以让这个过程更快</li>
<li>通过redis-cli一个一个操作太慢</li>
<li>通过pipeline操作,又会阻塞服务器</li>
<li>大数据量插入时,先按官网提到的协议生成对应格式的文本文件,然后使用redis-cli的管道模式批量导入</li>
</ol>
<h1 id="2-Partitioning"><a href="#2-Partitioning" class="headerlink" title="2. Partitioning"></a>2. Partitioning</h1><ol>
<li>将数据分布到不同的redis实例</li>
</ol>
<h2 id="2-1-分片策略"><a href="#2-1-分片策略" class="headerlink" title="2.1 分片策略"></a>2.1 分片策略</h2><ol>
<li>范围分片: 例如根据用户id的区间决定数据划分到哪个实例</li>
<li>hash分片: 先使用哈希函数求得哈希值,再通过取模根据结果例如介于0-3之间决定数据存储在哪个实例.少数客户端在这基础上实现了连续哈希</li>
<li>客户端分片: 在客户端就决定好读写的实例</li>
<li>代理分片: 客户端发送请求到代理,由代理决定实际的redis实例并返回响应给客户端,例如Twemproxy就应用这种模式</li>
<li>查询路由: 客户端发送请求到随机的一个redis实例,redis再转发请求到正确的节点.Redis Cluster 使用了这种模式,不同的是将客户端的连接重定向到正确的redis实例上而不是直接转发.</li>
</ol>
<h2 id="2-2-分片缺点"><a href="#2-2-分片缺点" class="headerlink" title="2.2 分片缺点"></a>2.2 分片缺点</h2><ol>
<li>分片后,不能直接对多个key一次操作</li>
<li>事务不能对多个key操作</li>
<li>像有序集合数据集被包含在一个大key中无法对内部key进行分片</li>
<li>增加操作复杂度,例如备份数据,需要整合各个实例的持久化文件</li>
<li>增加或减少容量比较复杂,Redis Cluster会重新平衡数据,当增加或者移除节点时.而使用客户端或代理分片方式则难以做到,Pre-sharding技术通过迁移实例的方式实现</li>
</ol>
<h1 id="3-Distributed-locks"><a href="#3-Distributed-locks" class="headerlink" title="3. Distributed locks"></a>3. Distributed locks</h1><ol>
<li>已经有多种库实现了分布式redis锁管理,具体<a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">https://redis.io/topics/distlock</a><h2 id="3-1-安全性和活跃度保证"><a href="#3-1-安全性和活跃度保证" class="headerlink" title="3.1 安全性和活跃度保证"></a>3.1 安全性和活跃度保证</h2></li>
<li>安全性: 互斥,同一个时刻只能有一个客户端拥有锁</li>
<li>死锁的释放: 例如当客户端锁住资源发生崩溃而其他客户端获取锁时</li>
<li>故障容错: 只要大部分redis节点存活,客户端就能进行正常的获取释放锁</li>
</ol>
<h2 id="3-2-故障转移缺陷例子"><a href="#3-2-故障转移缺陷例子" class="headerlink" title="3.2 故障转移缺陷例子"></a>3.2 故障转移缺陷例子</h2><ol>
<li>客户端A从主库获取对资源a的锁</li>
<li>对key的写入发送到从库前,主库崩溃</li>
<li>从库被提升为主库</li>
<li>客户端B从主库获取对资源a的锁,此时就违背了安全性原则</li>
</ol>
<h2 id="3-3-单实例的正确用法"><a href="#3-3-单实例的正确用法" class="headerlink" title="3.3 单实例的正确用法"></a>3.3 单实例的正确用法</h2><ol>
<li>使用setnx设置key的值,值必须全局唯一,释放锁时检查key是否存在,值是否与预期一致(第二条解释)</li>
<li>当客户端获取的锁的key带有过期时间.直接使用del最后释放锁的方式,如果过程中因为一些耗时操作导致key过期,此时其他客户端能够获取到锁,则最后del释放锁会把其他客户端的锁也释放.所以通过设置锁key的值作为签名并在最后使用del释放时做检查</li>
<li>使锁key的值唯一可以使用rc4根据具体信息生成对应随机字符串</li>
</ol>
<h2 id="3-4-Redlock-algorithm"><a href="#3-4-Redlock-algorithm" class="headerlink" title="3.4 Redlock algorithm"></a>3.4 Redlock algorithm</h2><ol>
<li>假设有5个redis独立主库</li>
<li>客户端先获取当前的时间毫秒级</li>
<li>顺序获取5个实例的锁,同样的key名和随机值.</li>
<li>客户端获取锁时,会设置一个相对锁过期时间很小的超时时间,如果一个实例获取不到锁超时则立刻获取下一个实例的</li>
<li>顺序获取实例锁时,锁的有效时间会逐渐递减,以最后获取实例的锁有效时间为准,最后每个实例锁的过期时间会是一致</li>
<li>如果已经存在N/2+1实例的锁key或者锁过期,则放弃获取所有实例的锁的操作.这就可以实现互斥原则,当一个客户端获取成功后,其他客户端可以因为没有获取到足够实例的锁而放弃</li>
<li>该算法基于假设所有机器和进程的时钟频率一致或相对于锁过期时间产生的误差可以忽略不计</li>
<li>当获取锁失败时,需要及时释放已获取的部分实例锁,可以避免需要等到key过期才能再次获取锁</li>
<li>文档对安全性和可用性进行了讨论,具体可以看文档</li>
<li>提高锁的性能可以通过使用非阻塞模式发送所有命令,再读取检查</li>
<li>需要设置持久化参数fsync=always避免断电或其他灾难后重启key丢失问题</li>
<li>算法对于断电或灾难重启后的实例不再参与现有活跃的锁.如果客户端A获取到3/5实例锁,而重启新增了一个实例,此时存在N/2+1实例的锁key条件不存在,其他客户端又可以获取锁了.解决问题的方法时,重启后保持一段不可用时间大于其他锁的过期时间.这里会引入一个问题就是如果多个实例重启,在这个不可用期间,意味着新的获取锁可能失败.</li>
<li>扩展可以考虑可重入锁的实现</li>
</ol>
<h1 id="4-Redis-Keyspace-Notifications"><a href="#4-Redis-Keyspace-Notifications" class="headerlink" title="4. Redis Keyspace Notifications"></a>4. Redis Keyspace Notifications</h1><ol>
<li>key空间报告通过发布订阅模式实现,默认不开启,可以通过配置文件开启</li>
<li>接收对key产生实际操作的事件</li>
</ol>
<h1 id="5-Secondary-indexing-with-Redis"><a href="#5-Secondary-indexing-with-Redis" class="headerlink" title="5. Secondary indexing with Redis"></a>5. Secondary indexing with Redis</h1><ol>
<li>redis主要通过key来获取数据,利用redis的一些数据结构可以创建二级索引<h2 id="5-1-有序集合的数值索引"><a href="#5-1-有序集合的数值索引" class="headerlink" title="5.1 有序集合的数值索引"></a>5.1 有序集合的数值索引</h2></li>
<li>通过有序集合的分值对数据对象进行索引</li>
<li>常见的操作为,hash结构存储数据对象集合,有序集合对数据对象创建索引</li>
<li>如果能将多维数据转为线性,则可以利用有序集合对数据进行list索引</li>
<li>两个分值一样的,则通过C函数memcmp比较</li>
</ol>
<h2 id="5-2-字典索引"><a href="#5-2-字典索引" class="headerlink" title="5.2 字典索引"></a>5.2 字典索引</h2><ol>
<li>ZRANGEBYLEX可以对值进行检索,包括或排除,可以利用在自动补全场景</li>
<li>可以再给值加上频率条件</li>
<li>考虑大小写条件时,可以按小写:频率:大写的方式存储值</li>
<li>使用组合索引,实际就是将多个字段信息组合后存储为有序集合</li>
<li>只要找到一种规则就可以合理利用ZRANGEBYLEX对数据进行查询</li>
</ol>
<h1 id="6-Replication"><a href="#6-Replication" class="headerlink" title="6. Replication"></a>6. Replication</h1><ol>
<li>主库发送将命令实时发送给从库</li>
<li>主从连接断开时会重连,并找回连接断开期间主库命令重新同步</li>
<li>如果找回断开期间部分的命令失败,则执行全部同步,具体由主库发送快照给从库,然后继续保持同步</li>
<li>从库复制异步进行,从库返回确认也是异步进行</li>
<li>如果从库落后主库,可以根据配置决定此时从库是否还可以使用旧的数据</li>
<li>主从复制的一个好处是可以避免主库持久化总是需要将数据写入磁盘,可以通过从库复制实时保存.然而需要注意的是,如果重启主库,主库数据集为空,从库同步复制主库时,从库数据也会被清空</li>
<li>建议在主从都开启持久化,或者如果不开启持久化则要避免重启机器后自动重启服务</li>
<li>每一个主库有一个replication id标识,对每个发送给从库的命令会有一个下标.如果从库断连后重连,则会告诉主库最后一个下标,并从该下标开始追赶执行命令同步主库</li>
<li>从新同步时,主库会开启一个存储进程生成RDB文件(写入磁盘),并缓存新接收的写命令.将RDB文件发送给从库,从库加载RDB文件到内存中,并接收主库缓存的命令然后继续同步</li>
<li>从库不会对key做expire操作,当主库key过期时执行del操作时发送到从库,从库执行</li>
<li>当访问从库已过期key时,因为主库的延迟操作,从库根据自身时钟做出判断报告该key不存在</li>
<li>主库执行Lua脚本时,时间被冻结,所以脚本必须同步到从库执行保证一致效果</li>
</ol>
<h1 id="7-Redis-Persistence"><a href="#7-Redis-Persistence" class="headerlink" title="7. Redis Persistence"></a>7. Redis Persistence</h1><h2 id="7-1-模式"><a href="#7-1-模式" class="headerlink" title="7.1 模式"></a>7.1 模式</h2><ol>
<li>RDB: 通过对某个时间点数据集存储为快照文件</li>
<li>AOF: 记录每一个写操作,通过重放方式初始化数据</li>
<li>可以在同一个实例中同时使用这两种模式,重启实例时,AOF模式用于从新初始化数据</li>
</ol>
<h2 id="7-2-RDB"><a href="#7-2-RDB" class="headerlink" title="7.2 RDB"></a>7.2 RDB</h2><ol>
<li>随心所欲对某个时间点的数据进行备份</li>
<li>适合用于灾难恢复</li>
<li>通过子进程完成备份,而父进程不用磁盘IO,不影响其他命令的进行</li>
<li>重启初始化数据更快</li>
<li>派生子进程,在数据集很大时会比较耗时.频繁备份对性能有一定损耗</li>
</ol>
<h2 id="7-3-AOF"><a href="#7-3-AOF" class="headerlink" title="7.3 AOF"></a>7.3 AOF</h2><ol>
<li>可以多种文件同步策略,每秒记录或每个写命令时记录,持续性更好</li>
<li>是一个只加文件,无需定位,容易修复</li>
<li>如果AOF文件太大时,redis会自动生成新的文件并切换到新的文件</li>
<li>如果不小心执行了FLUSHALL命令,只要还没有新的命令写入,停止实例.并将最后一个命令删除后重启redis就可以了</li>
</ol>
<h2 id="7-4-备份数据"><a href="#7-4-备份数据" class="headerlink" title="7.4 备份数据"></a>7.4 备份数据</h2><ol>
<li>redis会避免RDB和AOF的进程在同一时刻进行</li>
<li>建议设置定时任务生成每个小时的RDB文件放在一个文件夹和生成每天的RDB文件放在另一个文件夹</li>
<li>定时任务每次执行,清除比较老的RDB文件</li>
<li>每天转移RDB文件</li>
</ol>
<h1 id="8-Redis-Security"><a href="#8-Redis-Security" class="headerlink" title="8. Redis Security"></a>8. Redis Security</h1><ol>
<li>网络安全策略,将redis运行在虚拟化的linux实例避免直接暴露,外部无法通过防火墙连接redis,客户端通过环回地址与对应端口通信</li>
<li>安全模式: 从3.2.0版本开始,如果在配置上允许绑定所有端口,而且外部访问无需密码时会进入安全模式,只有通过环回地址的才能够正常访问,其他的客户端返回错误</li>
<li>认证功能: 密码应该设置足够长</li>
<li>数据加密: redis并不支持,不过可以再加一层SSL代理.redis推荐Spiped做对称加密</li>
<li>设置一些命令不可用</li>
<li>NoSQL注入: 注意从不可信赖来源获取可能为Lua脚本作为字符串的问题</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/redis-2/" data-id="cjsvjedgq000zlwt95ido10mt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-redis-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/redis-1/" class="article-date">
  <time datetime="2018-06-30T06:41:04.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/redis-1/">Redis文档阅读笔记一</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-Pipelining"><a href="#1-Pipelining" class="headerlink" title="1. Pipelining"></a>1. Pipelining</h1><ol>
<li>Redis是一个TCPServer,使用CS模型</li>
<li>1次请求将命令集合发送,Redis执行命令后将结果队列化后,再写入返回</li>
<li>队列化执行结果需要使用内存,如果多次大批量操作需要注意内存的使用</li>
<li>使用Redis脚本能够处理更快处理批量命令.管道无法在脚本中使用,因为使用管道时在写入之前需要返回响应给客户端(需要注意:这里个人理解可能存在偏差).反之,管道可以使用脚本</li>
</ol>
<h1 id="2-Redis-Pub-Sub"><a href="#2-Redis-Pub-Sub" class="headerlink" title="2. Redis Pub/Sub"></a>2. Redis Pub/Sub</h1><ol>
<li>发布订阅模式: 发布者发布消息到Channel,订阅者订阅Channel接收消息</li>
<li>Redis客户端一旦为订阅模式,不能接收其他命令</li>
<li>redis-cli命令行客户端时进入订阅模式之后只能通过ctrl-c取消订阅,因为此时客户端阻塞等待接收订阅消息</li>
<li>发布订阅无关于key所在空间,db10发布的,db1订阅仍能接收</li>
<li>可用模式匹配发布多个channel 和订阅多个channel</li>
</ol>
<h1 id="3-Redis-Lua-scripting"><a href="#3-Redis-Lua-scripting" class="headerlink" title="3. Redis Lua scripting"></a>3. Redis Lua scripting</h1><ol>
<li>EVAL,EVALSHA命令执行Lua脚本</li>
<li>Lua 脚本可以使用redis.call 或redis.pcall执行redis命令</li>
<li>redis.call执行遇到错误时直接抛出Lua异常结果,redis.pcall则会把异常处理成Lua table返回</li>
<li>Lua调用redis命令时把数据转成redis对应数据类型,脚本执行结果返回给客户端时Lua的数据类型转成redis对应数据类型</li>
<li>使用Lua脚本时对于浮点数最好使用字符串替代</li>
<li>如果Lua返回数组中包含nil,则数据转换终止,最终只能返回nil之前的结果</li>
<li>redis.error_reply,redis.status_reply 在Lua脚本中是比较有用的按redis数据类型返回结果的方法</li>
<li>执行Lua脚本时,其他客户端的命令和脚本将无法执行</li>
<li>redis内部缓存机制会缓存脚本,使用EVALSHA,如果redis通过匹配SHA1文摘匹配到脚本,则执行脚本,否则返回错误信息通知使用EVAL代替</li>
<li>使用SCRIPT FLUSH或重启redis实例会刷新脚本缓存</li>
<li>脚本自身会被从库复制或写入AOF文件,而不是脚本的结果命令.不过从3.2版本开始,已经可选设置复制结果命令</li>
<li>脚本不允许设置全局变量</li>
</ol>
<h1 id="4-Debugging-Lua-scripts"><a href="#4-Debugging-Lua-scripts" class="headerlink" title="4. Debugging Lua scripts"></a>4. Debugging Lua scripts</h1><ol>
<li>Redis Lua debugger默认,每一个新的Debug session是一个forked session,这意味着当脚本在debug中时,不会阻塞redis server执行其他命令,同时也意味着debug结束后会回滚脚本执行的结果</li>
<li>官网有视频详解<a href="https://redis.io/topics/ldb" target="_blank" rel="noopener">https://redis.io/topics/ldb</a></li>
</ol>
<h1 id="5-Memory-optimization"><a href="#5-Memory-optimization" class="headerlink" title="5. Memory optimization"></a>5. Memory optimization</h1><ol>
<li>通过修改redis.conf调整每一种数据类型的最大数量和最大空间</li>
<li>RDB和AOF文件兼容32位和64位,之间可以互转</li>
<li>合理利用bit和byte操作</li>
<li>尽可能使用hash结构存储数据</li>
<li>每个hash最多存储100个field是cpu和内存之间的最佳妥协</li>
<li>redis根据配置文件maxmemory分配内存</li>
<li>被删除的key实际上并不会立刻释放内存,例如在同一页中存在其他的key未被删除,需要根据峰值内存使用量限定内存使用</li>
<li>redis底层内存分配器会尽可能重复利用被删除key的内存,所以也不用太担心被删除key没有及时释放的问题</li>
<li>如果不设置maxmemory,所有的内存将可能被吃光</li>
<li>当超过最大内存限制时,导致写入时out of memory error,但不会因此导致整个机器挂掉</li>
</ol>
<h1 id="6-Expires"><a href="#6-Expires" class="headerlink" title="6. Expires"></a>6. Expires</h1><ol>
<li>过期时间只针对key不针对值</li>
<li>过期时间可以通过persist命令清除</li>
<li>通过rename重命名key,原key的过期时间仍然有效,如果由别的key rename覆盖,则该key具有别的key的特性</li>
<li>如果设置的过期时间为过去时间,则key相当于del 而不是expired</li>
<li>消极检查: 当客户端获取该key时才检查该key是否过期</li>
<li>积极检查: redis 1秒内执行10个检查过期,每次随机选取20个key,发现过期的则清除,如果发现超过25%过期,则继续下一个检查</li>
<li>过期执行删除的命令会传递给从库和AOF文件同步执行.从库不会检查key过期,当切换为主库时才会去检查</li>
</ol>
<h1 id="7-Redis-as-an-LRU-Less-Recently-Used-cache"><a href="#7-Redis-as-an-LRU-Less-Recently-Used-cache" class="headerlink" title="7. Redis as an LRU (Less Recently Used) cache"></a>7. Redis as an LRU (Less Recently Used) cache</h1><h2 id="7-1-Redis达到最大内存限制时策略"><a href="#7-1-Redis达到最大内存限制时策略" class="headerlink" title="7.1 Redis达到最大内存限制时策略"></a>7.1 Redis达到最大内存限制时策略</h2><ol>
<li>noeviction: 直接抛出异常</li>
<li>allkeys-lru: 将最近不常用的key清除腾出空间</li>
<li>volatile-lru: 将带有过期时间的最近不常用的key清除腾出空间</li>
<li>allkeys-random: 随机将key清除腾出空间</li>
<li>volatile-random: 随机将带有过期时间的key清除腾出空间</li>
<li>volatile-ttl: 将较小剩余存活时间的key清除腾出空间</li>
<li>如果不确定使用哪种策略,allkeys-lru是一个较好选择</li>
<li>volatile-lru和volatile-random比较适用于只用单个实例,混用缓存和持久key</li>
</ol>
<h2 id="7-2-近似LRU算法"><a href="#7-2-近似LRU算法" class="headerlink" title="7.2 近似LRU算法"></a>7.2 近似LRU算法</h2><ol>
<li>redis使用的并不是实际的LRU算法,而是大致评估一定样本量中选取最符合的key</li>
<li>可以通过设置配置样本量参数maxmemory-samples调节精度</li>
</ol>
<h2 id="7-3-LFU-Least-Frequently-Used"><a href="#7-3-LFU-Least-Frequently-Used" class="headerlink" title="7.3 LFU (Least Frequently Used)"></a>7.3 LFU (Least Frequently Used)</h2><ol>
<li>4.0版本以后新增了新策略,根据命中的频率决定清除哪些key</li>
<li>lfu-log-factor和lfu-decay-time是两项主要调节参数</li>
</ol>
<h1 id="8-Redis-transactions"><a href="#8-Redis-transactions" class="headerlink" title="8. Redis transactions"></a>8. Redis transactions</h1><ol>
<li>事务中的所有命令会序列化并串行化执行,在事务过程中,其他客户端发起的请求不会被处理</li>
<li>所有命令要么全部被处理或不处理(这里的处理并不表示一定执行成功),保证了原子性</li>
<li>如果使用append-only file,在发生崩溃或强制关闭redis时有可能导致执行事务中部分命令.redis重启后会检测到直接退出.使用redis-check-aof tool修复</li>
<li>MULTI开启事务,命令存储到队列,命令EXEC执行事务所有命令</li>
<li>执行EXEC检测到命令错误时,会在EXEC直接返回错误信息,并丢弃所有命令</li>
<li>执行EXEC后,部分命令执行失败,对应的命令返回错误信息,其他命令执行成功</li>
<li>redis不支持回滚:因为官方认为不需要,语法上的错误,在命令队列化时就能检测到,而编码错误导致命令执行失败redis表示不背这个锅,redis追求更简单,更快</li>
<li>使用WATCH命令实现乐观锁,如果多个客户端对同一个key进行操作并存储时,被观察的key被改变后,其他客户端对该key的修改的事务则会失败,实现了对该key的原子操作</li>
<li>需要注意的一点,当WATCH某个key之后,key过期了,那EXEC就会正常执行</li>
<li>使用WATCH可以实现对有序集合操作的原子性</li>
<li>对事务的操作在脚本中也能实现,而且脚本可以更简单更快</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/redis-1/" data-id="cjsvjedfx000blwt91ws97fjn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mysql-6" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/mysql-6/" class="article-date">
  <time datetime="2018-06-30T06:21:03.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/《高性能MySQL》阅读笔记/">《高性能MySQL》阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/mysql-6/">《高性能MySQL》阅读笔记六</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-可扩展的Mysql"><a href="#1-可扩展的Mysql" class="headerlink" title="1. 可扩展的Mysql"></a>1. 可扩展的Mysql</h1><p>可扩展性: 通过增加资源提升容量的能力</p>
<h2 id="1-1-考虑负载"><a href="#1-1-考虑负载" class="headerlink" title="1.1 考虑负载"></a>1.1 考虑负载</h2><p>容量可以简单地认为是处理负载的能力,考虑负载可从以下几个角度</p>
<ol>
<li>数据量: 很多应用从不物理删除任何数据,应用所积累的数据量是可扩展的普遍挑战</li>
<li>用户量: 更多的用户意味着更多的事务,更多的复杂查询</li>
<li>用户活跃度</li>
<li>相关数据集的大小</li>
</ol>
<h2 id="1-2-规划可扩展性"><a href="#1-2-规划可扩展性" class="headerlink" title="1.2 规划可扩展性"></a>1.2 规划可扩展性</h2><ol>
<li>估算需要承担的负载到底有多少</li>
<li>大致正确地估计日程表</li>
<li>应用的功能完成多少</li>
<li>预期的最大负载是多少</li>
<li>如果依赖系统的每个部分分担负载,某个部分失效时会发生什么</li>
</ol>
<h2 id="1-3-向上扩展-垂直扩展"><a href="#1-3-向上扩展-垂直扩展" class="headerlink" title="1.3 向上扩展(垂直扩展)"></a>1.3 向上扩展(垂直扩展)</h2><ol>
<li>单台服务器增加各种高性能硬件</li>
<li>烧钱有效的方法</li>
<li>不应该无限制向上扩展</li>
</ol>
<h2 id="1-4-向外扩展"><a href="#1-4-向外扩展" class="headerlink" title="1.4 向外扩展"></a>1.4 向外扩展</h2><ol>
<li>策略: 复制,拆分,数据分片</li>
<li>按功能拆分: 常见做法,根据功能将应用部署在不同服务器,并使用专用的数据库服务器</li>
</ol>
<h3 id="1-4-1-数据分片"><a href="#1-4-1-数据分片" class="headerlink" title="1.4.1 数据分片"></a>1.4.1 数据分片</h3><p>数据分片是目前扩展大型MySQL最通用且最成功的方法</p>
<ol>
<li>应用设计初期考虑到,后期实现就比较容易,否则很难将应用从单一数据存储转换为分片架构</li>
<li>文中举例: 通过用户id来对文章和评论进行分片,而将用户的信息保留在单个节点上</li>
<li>数据库访问抽象层,降低应用和分片数据之间通信的复杂度</li>
<li>如非必要尽量不分片</li>
<li>数据分片最大的挑战就是查找和获取数据</li>
<li>类似于表分区,选择分区键和数据分片方式是关键,具体请细查</li>
</ol>
<h2 id="1-5-通过集群扩展"><a href="#1-5-通过集群扩展" class="headerlink" title="1.5 通过集群扩展"></a>1.5 通过集群扩展</h2><ol>
<li>可以使用集群或数据库分布式技术根据场景适当解决一些问题</li>
<li>书中提到技术: NDB Cluster, Clustrix等技术</li>
</ol>
<h2 id="1-6-向内扩展"><a href="#1-6-向内扩展" class="headerlink" title="1.6 向内扩展"></a>1.6 向内扩展</h2><ol>
<li>对不再需要的数据进行归档和清理</li>
<li>需要考虑对应用的影响</li>
<li>需要考虑数据逻辑的一致性,例如清理A表历史数据时需要考虑所有关联数据的处理</li>
<li>冷热数据分离</li>
</ol>
<h2 id="1-7-负载均衡"><a href="#1-7-负载均衡" class="headerlink" title="1.7 负载均衡"></a>1.7 负载均衡</h2><h3 id="1-7-1-目的"><a href="#1-7-1-目的" class="headerlink" title="1.7.1 目的"></a>1.7.1 目的</h3><ol>
<li>可扩展性: 如读写分离时从备库读数据</li>
<li>高效性: 把更多工作分配给更好的机器</li>
<li>可用性: 使用时刻保持可用的服务器</li>
<li>透明性: 客户端无需知道服务器</li>
<li>一致性: 如果应用是有状态的,负载均衡器就应该将相关的查询指向同一个服务器</li>
</ol>
<h3 id="1-7-2-直接连接"><a href="#1-7-2-直接连接" class="headerlink" title="1.7.2 直接连接"></a>1.7.2 直接连接</h3><h4 id="1-7-2-1-复制上的读写分离"><a href="#1-7-2-1-复制上的读写分离" class="headerlink" title="1.7.2.1 复制上的读写分离"></a>1.7.2.1 复制上的读写分离</h4><ol>
<li>基于查询分离: 将不能容忍脏数据的查询分配到主库,其他分配到备库</li>
<li>基于脏数据分离: 让应用检查复制延迟,许多报表类应用使用这个策略</li>
<li>基于会话分离: 可以在会话层做一个标记,如果用户修改了数据,则一段时间内总是指向主库</li>
<li>基于版本分离: 给用户的操作增加版本号,检查版本号决定从主库还是备库读取数据</li>
</ol>
<h4 id="1-7-2-3-修改DNS名"><a href="#1-7-2-3-修改DNS名" class="headerlink" title="1.7.2.3 修改DNS名"></a>1.7.2.3 修改DNS名</h4><ol>
<li>通过变更DNS名指定的服务器实现</li>
<li>缺点很多,不建议</li>
</ol>
<h4 id="1-7-2-4-转移IP地址"><a href="#1-7-2-4-转移IP地址" class="headerlink" title="1.7.2.4 转移IP地址"></a>1.7.2.4 转移IP地址</h4><ol>
<li>在服务器之间转移虚拟地址</li>
<li>给服务器分配固定的ip地址,为每个逻辑上的服务使用一个虚拟ip地址</li>
</ol>
<h3 id="1-7-3-引入中间件"><a href="#1-7-3-引入中间件" class="headerlink" title="1.7.3 引入中间件"></a>1.7.3 引入中间件</h3><ol>
<li>负载均衡器,如HAproxy</li>
<li>负载均衡算法: 随机, 轮询,最少连接数,最快响应,哈希,权重</li>
<li>服务器池中增加或移除服务器: 在配置连接池中的服务器时,要保证有足够多未使用的容量</li>
</ol>
<h1 id="2-高可用性"><a href="#2-高可用性" class="headerlink" title="2. 高可用性"></a>2. 高可用性</h1><ol>
<li>高可用性意味着更少的宕机时间<h2 id="2-1-宕机原因"><a href="#2-1-宕机原因" class="headerlink" title="2.1 宕机原因"></a>2.1 宕机原因</h2></li>
<li>磁盘空间不足</li>
<li>糟糕的sql或者服务器bug引起</li>
<li>糟糕的表和索引设计</li>
<li>复制问题通常由于主备数据不一致导致</li>
</ol>
<h2 id="2-2-高可用性实现"><a href="#2-2-高可用性实现" class="headerlink" title="2.2 高可用性实现"></a>2.2 高可用性实现</h2><ol>
<li>衡量指标: 平均失效时间(MTBF), 平均恢复时间(MTTR)</li>
<li>避免问题: 适当的配置,监控和规范</li>
<li>保证在宕机时能快速恢复,系统制造冗余,具备故障转移能力</li>
</ol>
<h3 id="2-2-1-避免单点失效"><a href="#2-2-1-避免单点失效" class="headerlink" title="2.2.1 避免单点失效"></a>2.2.1 避免单点失效</h3><ol>
<li>通过增加冗余避免</li>
<li>共享存储或磁盘复制,如果服务器挂了,备用服务器可以挂载相同的文件系统执行需要的恢复操作</li>
<li>MySQL同步复制</li>
</ol>
<h3 id="2-2-2-故障转移和故障恢复"><a href="#2-2-2-故障转移和故障恢复" class="headerlink" title="2.2.2 故障转移和故障恢复"></a>2.2.2 故障转移和故障恢复</h3><ol>
<li>提升备库或切换角色</li>
<li>虚拟IP地址或IP接管: 当MySQL实例失效时可以将IP地址转移到另一台MySQL服务器上</li>
<li>使用中间件解决方案</li>
</ol>
<h1 id="3-备份与恢复"><a href="#3-备份与恢复" class="headerlink" title="3. 备份与恢复"></a>3. 备份与恢复</h1><h2 id="3-1-设计MySQL备份方案考虑点"><a href="#3-1-设计MySQL备份方案考虑点" class="headerlink" title="3.1 设计MySQL备份方案考虑点"></a>3.1 设计MySQL备份方案考虑点</h2><ol>
<li>在线备份还是离线备份</li>
<li>逻辑备份还是物理备份</li>
<li>非显著数据: 如二进制日志和InnoDB事务日志</li>
<li>代码: 存储过程,触发器</li>
<li>服务器配置和复制配置</li>
<li>外部配置,管理脚本</li>
<li>增量备份和差异备份</li>
<li>存储引擎和数据一致性</li>
</ol>
<h2 id="3-2-备份数据方式"><a href="#3-2-备份数据方式" class="headerlink" title="3.2 备份数据方式"></a>3.2 备份数据方式</h2><ol>
<li>文件系统中或SAN快照中直接复制数据文件</li>
<li>Percona XtraBackup 做热备份</li>
</ol>
<h2 id="3-3-InnoDB崩溃恢复"><a href="#3-3-InnoDB崩溃恢复" class="headerlink" title="3.3 InnoDB崩溃恢复"></a>3.3 InnoDB崩溃恢复</h2><ol>
<li>二级索引损坏: 使用OPTIMIZE TABLE修复损坏的二级索引,此外可以通过构建一个新表重建受影响的索引</li>
<li>聚簇索引损坏: innodb_force_recovery导出表</li>
<li>损坏系统结构: 系统结构包括事务日志等,可能需要做整个数据库的导出和还原,因为InnoDB内部绝大部分的工作可能受影响</li>
</ol>
<h1 id="4-MySQL用户工具"><a href="#4-MySQL用户工具" class="headerlink" title="4. MySQL用户工具"></a>4. MySQL用户工具</h1><p>工欲善其事,必先利其器</p>
<h2 id="4-1-接口工具"><a href="#4-1-接口工具" class="headerlink" title="4.1 接口工具"></a>4.1 接口工具</h2><ol>
<li>MySQL Workbench: 一站式的工具</li>
<li>SQLyog: 可视化工具之一</li>
</ol>
<h2 id="4-2-命令行工具集"><a href="#4-2-命令行工具集" class="headerlink" title="4.2 命令行工具集"></a>4.2 命令行工具集</h2><ol>
<li>Percona Toolkit</li>
<li>MySQL Workbench 工具集</li>
</ol>
<h2 id="4-3-SQL实用集"><a href="#4-3-SQL实用集" class="headerlink" title="4.3 SQL实用集"></a>4.3 SQL实用集</h2><ol>
<li>common_schema</li>
<li>MySQL Forge</li>
</ol>
<h2 id="4-4-监测工具"><a href="#4-4-监测工具" class="headerlink" title="4.4 监测工具"></a>4.4 监测工具</h2><ol>
<li>Nagios</li>
<li>Zabbix: 同时支持监控和指标收集的完整系统</li>
<li>Zenoss: Python写的</li>
<li>Hyperic HQ: 基于Java</li>
</ol>
<h2 id="4-5-Innotop命令行监控"><a href="#4-5-Innotop命令行监控" class="headerlink" title="4.5 Innotop命令行监控"></a>4.5 Innotop命令行监控</h2><p>主要包括以下功能</p>
<ol>
<li>事务列表</li>
<li>当前运行的查询</li>
<li>当前锁和锁等待列表</li>
<li>服务器状态和变量汇总信息</li>
<li>InnoDB内部信息</li>
<li>复制监控</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/mysql-6/" data-id="cjsvjedfp0003lwt9bhv4jwyf" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx文档笔记/">Nginx文档笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python源码学习/">Python源码学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《HTTP权威指南》阅读笔记/">《HTTP权威指南》阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《TCP-IP详解卷1》阅读笔记/">《TCP/IP详解卷1》阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《现代操作系统》阅读笔记/">《现代操作系统》阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《高性能MySQL》阅读笔记/">《高性能MySQL》阅读笔记</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/09/18/tcpip-1/">《TCP/IP详解卷1》阅读笔记一</a>
          </li>
        
          <li>
            <a href="/2018/08/18/opsystem-1/">《现代操作系统》阅读笔记一</a>
          </li>
        
          <li>
            <a href="/2018/08/18/opsystem-2/">《现代操作系统》阅读笔记二</a>
          </li>
        
          <li>
            <a href="/2018/08/18/opsystem-3/">《现代操作系统》阅读笔记三</a>
          </li>
        
          <li>
            <a href="/2018/07/26/nginx-1/">Nginx文档笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Whales<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>