<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>沧海一粟</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="沧海一粟">
<meta property="og:url" content="https://whales2018.github.io/index.html">
<meta property="og:site_name" content="沧海一粟">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="沧海一粟">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">沧海一粟</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://whales2018.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-amqp" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/17/amqp/" class="article-date">
  <time datetime="2018-07-17T14:44:38.000Z" itemprop="datePublished">2018-07-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python源码学习/">Python源码学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/17/amqp/">Python amqp源码学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p>amqp的源码比较少，适合我们学习AMQP的相关知识，先看看包结构</p>
<p><img src="http://pcyw0skfm.bkt.clouddn.com/2018-08-05%2011-03-26%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
<p>通过快速阅读，大致总结一下数据的转换和处理过程，如下图</p>
<p><img src="http://pcyw0skfm.bkt.clouddn.com/amqp_1.jpg" alt=""></p>
<p>阅读源码之前我们需要明确几个目标及关键点</p>
<ol>
<li>报文结构，跟TCP/IP协议类似，通过了解AMQP报文的结构我们才能更好地理解代码的设计及处理。</li>
<li>数据转换处理</li>
<li>消息收发，状态转换</li>
<li>设计思想及细节处理</li>
</ol>
<h3 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h3><h3 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h3><h4 id="serialization-py"><a href="#serialization-py" class="headerlink" title="serialization.py"></a>serialization.py</h4><ul>
<li><p>AMQPReader: 将二进制数据转换为Python数据类型数据,使用标准库struct处理二进制数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 提供一个统一的读取数据方法</span><br><span class="line">def read_item(self):</span><br><span class="line">    # 从二进制流读取第一字节，作为数据类型标识</span><br><span class="line">    ftype = ord(self.input.read(1))</span><br><span class="line"></span><br><span class="line">    if ftype == 83:</span><br><span class="line">        val = self.read_longstr()</span><br><span class="line"></span><br><span class="line">def read_longstr(self):</span><br><span class="line">    # 这里的bitcount和bits设置为0,标志如果下一次使用read_bit,该函数将会重新读取一字节</span><br><span class="line">    self.bitcount = self.bits = 0</span><br><span class="line">    # 接着从二进制流读取4字节,获取接下来的多少字节数据属于要读取的值</span><br><span class="line">    slen = unpack(&apos;&gt;I&apos;, self.input.read(4))[0]</span><br><span class="line">    return self.input.read(slen).decode(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def read_bit(self):</span><br><span class="line">    # 读取单个bit,如果是连续调用则从单个字节中继续读取单个bit</span><br><span class="line">    if not self.bitcount:</span><br><span class="line">        self.bits = ord(self.input.read(1))</span><br><span class="line">        self.bitcount = 8</span><br><span class="line">    result = (self.bits &amp; 1) == 1</span><br><span class="line">    self.bits &gt;&gt;= 1</span><br><span class="line">    self.bitcount -= 1</span><br><span class="line">    return result</span><br></pre></td></tr></table></figure>
</li>
<li><p>AMQRWriter: 将Python数据类型数据转换为二进制数据</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 与AMQPReader对不同数据类型的做相对应的处理</span><br><span class="line">def write_item(self, v, k=None):</span><br><span class="line">    elif isinstance(v, bool):</span><br><span class="line">        self.write(pack(&apos;&gt;cB&apos;, b&apos;t&apos;, int(v)))</span><br><span class="line">    elif isinstance(v, float):</span><br><span class="line">        self.write(pack(&apos;&gt;cd&apos;, b&apos;d&apos;, v))</span><br><span class="line"></span><br><span class="line">def write_bit(self, b):</span><br><span class="line">    # 这一步主要是每8个bit数值结果用一个整数代替，配合_flushbits</span><br><span class="line">    # 如果是连续调用，则将会更加节省传递数据量</span><br><span class="line">    &quot;&quot;&quot;Write a boolean value.&quot;&quot;&quot;</span><br><span class="line">    b = 1 if b else 0</span><br><span class="line">    shift = self.bitcount % 8</span><br><span class="line">    if shift == 0:</span><br><span class="line">        self.bits.append(0)</span><br><span class="line">    self.bits[-1] |= (b &lt;&lt; shift)</span><br><span class="line">    self.bitcount += 1</span><br><span class="line"></span><br><span class="line">def _flushbits(self):</span><br><span class="line">    if self.bits:</span><br><span class="line">        out = self.out</span><br><span class="line">        for b in self.bits:</span><br><span class="line">            out.write(pack(&apos;B&apos;, b))</span><br><span class="line">        self.bits = []</span><br><span class="line">        self.bitcount = 0</span><br></pre></td></tr></table></figure>
<ul>
<li>GenericContent</li>
</ul>
<p>amqp内容消息体基类，序列化和反序列化内容头部属性信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def _load_properties(self, raw_bytes):</span><br><span class="line">    ...</span><br><span class="line">    # 通过预设置各个消息体的头部标识映射到AMQPReader对应的读取方法</span><br><span class="line"></span><br><span class="line">def _serialize_properties(self):</span><br><span class="line">    # 通过预设置各个消息体的头部标识映射到AMQRWriter对应的写入数据方法</span><br></pre></td></tr></table></figure>
<h4 id="basic-message-py"><a href="#basic-message-py" class="headerlink" title="basic_message.py"></a>basic_message.py</h4><p>Message: amqp内容消息体基类，继承自GenericContent</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">class Message(GenericContent):</span><br><span class="line">    &quot;&quot;&quot;A Message for use with the Channnel.basic_* methods.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 默认可选的属性值将会在客户端和服务端之间传递</span><br><span class="line">    # 每种属性分别对应的数据类型决定了读取和写入的方法</span><br><span class="line">    PROPERTIES = [</span><br><span class="line">        (&apos;content_type&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;content_encoding&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;application_headers&apos;, &apos;table&apos;),</span><br><span class="line">        (&apos;delivery_mode&apos;, &apos;octet&apos;),</span><br><span class="line">        (&apos;priority&apos;, &apos;octet&apos;),</span><br><span class="line">        (&apos;correlation_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;reply_to&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;expiration&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;message_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;timestamp&apos;, &apos;timestamp&apos;),</span><br><span class="line">        (&apos;type&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;user_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;app_id&apos;, &apos;shortstr&apos;),</span><br><span class="line">        (&apos;cluster_id&apos;, &apos;shortstr&apos;)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def __init__(self, body=&apos;&apos;, children=None, channel=None, **properties):</span><br><span class="line">        # 具体使用了哪些属性值还是需要根据不同实例传入的properties参数</span><br></pre></td></tr></table></figure>
<h4 id="method-framing-py"><a href="#method-framing-py" class="headerlink" title="method_framing.py"></a>method_framing.py</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/07/17/amqp/" data-id="cjscy3my700003jzlog2as3bh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-redis-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/redis-2/" class="article-date">
  <time datetime="2018-06-30T06:47:41.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/redis-2/">Redis文档阅读笔记二</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-Redis-Mass-Insertion"><a href="#1-Redis-Mass-Insertion" class="headerlink" title="1. Redis Mass Insertion"></a>1. Redis Mass Insertion</h1><ol>
<li>有时候需要将原先存有的大量数据迁移到新的redis实例,redis提供一些方案可以让这个过程更快</li>
<li>通过redis-cli一个一个操作太慢</li>
<li>通过pipeline操作,又会阻塞服务器</li>
<li>大数据量插入时,先按官网提到的协议生成对应格式的文本文件,然后使用redis-cli的管道模式批量导入</li>
</ol>
<h1 id="2-Partitioning"><a href="#2-Partitioning" class="headerlink" title="2. Partitioning"></a>2. Partitioning</h1><ol>
<li>将数据分布到不同的redis实例</li>
</ol>
<h2 id="2-1-分片策略"><a href="#2-1-分片策略" class="headerlink" title="2.1 分片策略"></a>2.1 分片策略</h2><ol>
<li>范围分片: 例如根据用户id的区间决定数据划分到哪个实例</li>
<li>hash分片: 先使用哈希函数求得哈希值,再通过取模根据结果例如介于0-3之间决定数据存储在哪个实例.少数客户端在这基础上实现了连续哈希</li>
<li>客户端分片: 在客户端就决定好读写的实例</li>
<li>代理分片: 客户端发送请求到代理,由代理决定实际的redis实例并返回响应给客户端,例如Twemproxy就应用这种模式</li>
<li>查询路由: 客户端发送请求到随机的一个redis实例,redis再转发请求到正确的节点.Redis Cluster 使用了这种模式,不同的是将客户端的连接重定向到正确的redis实例上而不是直接转发.</li>
</ol>
<h2 id="2-2-分片缺点"><a href="#2-2-分片缺点" class="headerlink" title="2.2 分片缺点"></a>2.2 分片缺点</h2><ol>
<li>分片后,不能直接对多个key一次操作</li>
<li>事务不能对多个key操作</li>
<li>像有序集合数据集被包含在一个大key中无法对内部key进行分片</li>
<li>增加操作复杂度,例如备份数据,需要整合各个实例的持久化文件</li>
<li>增加或减少容量比较复杂,Redis Cluster会重新平衡数据,当增加或者移除节点时.而使用客户端或代理分片方式则难以做到,Pre-sharding技术通过迁移实例的方式实现</li>
</ol>
<h1 id="3-Distributed-locks"><a href="#3-Distributed-locks" class="headerlink" title="3. Distributed locks"></a>3. Distributed locks</h1><ol>
<li>已经有多种库实现了分布式redis锁管理,具体<a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">https://redis.io/topics/distlock</a><h2 id="3-1-安全性和活跃度保证"><a href="#3-1-安全性和活跃度保证" class="headerlink" title="3.1 安全性和活跃度保证"></a>3.1 安全性和活跃度保证</h2></li>
<li>安全性: 互斥,同一个时刻只能有一个客户端拥有锁</li>
<li>死锁的释放: 例如当客户端锁住资源发生崩溃而其他客户端获取锁时</li>
<li>故障容错: 只要大部分redis节点存活,客户端就能进行正常的获取释放锁</li>
</ol>
<h2 id="3-2-故障转移缺陷例子"><a href="#3-2-故障转移缺陷例子" class="headerlink" title="3.2 故障转移缺陷例子"></a>3.2 故障转移缺陷例子</h2><ol>
<li>客户端A从主库获取对资源a的锁</li>
<li>对key的写入发送到从库前,主库崩溃</li>
<li>从库被提升为主库</li>
<li>客户端B从主库获取对资源a的锁,此时就违背了安全性原则</li>
</ol>
<h2 id="3-3-单实例的正确用法"><a href="#3-3-单实例的正确用法" class="headerlink" title="3.3 单实例的正确用法"></a>3.3 单实例的正确用法</h2><ol>
<li>使用setnx设置key的值,值必须全局唯一,释放锁时检查key是否存在,值是否与预期一致(第二条解释)</li>
<li>当客户端获取的锁的key带有过期时间.直接使用del最后释放锁的方式,如果过程中因为一些耗时操作导致key过期,此时其他客户端能够获取到锁,则最后del释放锁会把其他客户端的锁也释放.所以通过设置锁key的值作为签名并在最后使用del释放时做检查</li>
<li>使锁key的值唯一可以使用rc4根据具体信息生成对应随机字符串</li>
</ol>
<h2 id="3-4-Redlock-algorithm"><a href="#3-4-Redlock-algorithm" class="headerlink" title="3.4 Redlock algorithm"></a>3.4 Redlock algorithm</h2><ol>
<li>假设有5个redis独立主库</li>
<li>客户端先获取当前的时间毫秒级</li>
<li>顺序获取5个实例的锁,同样的key名和随机值.</li>
<li>客户端获取锁时,会设置一个相对锁过期时间很小的超时时间,如果一个实例获取不到锁超时则立刻获取下一个实例的</li>
<li>顺序获取实例锁时,锁的有效时间会逐渐递减,以最后获取实例的锁有效时间为准,最后每个实例锁的过期时间会是一致</li>
<li>如果已经存在N/2+1实例的锁key或者锁过期,则放弃获取所有实例的锁的操作.这就可以实现互斥原则,当一个客户端获取成功后,其他客户端可以因为没有获取到足够实例的锁而放弃</li>
<li>该算法基于假设所有机器和进程的时钟频率一致或相对于锁过期时间产生的误差可以忽略不计</li>
<li>当获取锁失败时,需要及时释放已获取的部分实例锁,可以避免需要等到key过期才能再次获取锁</li>
<li>文档对安全性和可用性进行了讨论,具体可以看文档</li>
<li>提高锁的性能可以通过使用非阻塞模式发送所有命令,再读取检查</li>
<li>需要设置持久化参数fsync=always避免断电或其他灾难后重启key丢失问题</li>
<li>算法对于断电或灾难重启后的实例不再参与现有活跃的锁.如果客户端A获取到3/5实例锁,而重启新增了一个实例,此时存在N/2+1实例的锁key条件不存在,其他客户端又可以获取锁了.解决问题的方法时,重启后保持一段不可用时间大于其他锁的过期时间.这里会引入一个问题就是如果多个实例重启,在这个不可用期间,意味着新的获取锁可能失败.</li>
<li>扩展可以考虑可重入锁的实现</li>
</ol>
<h1 id="4-Redis-Keyspace-Notifications"><a href="#4-Redis-Keyspace-Notifications" class="headerlink" title="4. Redis Keyspace Notifications"></a>4. Redis Keyspace Notifications</h1><ol>
<li>key空间报告通过发布订阅模式实现,默认不开启,可以通过配置文件开启</li>
<li>接收对key产生实际操作的事件</li>
</ol>
<h1 id="5-Secondary-indexing-with-Redis"><a href="#5-Secondary-indexing-with-Redis" class="headerlink" title="5. Secondary indexing with Redis"></a>5. Secondary indexing with Redis</h1><ol>
<li>redis主要通过key来获取数据,利用redis的一些数据结构可以创建二级索引<h2 id="5-1-有序集合的数值索引"><a href="#5-1-有序集合的数值索引" class="headerlink" title="5.1 有序集合的数值索引"></a>5.1 有序集合的数值索引</h2></li>
<li>通过有序集合的分值对数据对象进行索引</li>
<li>常见的操作为,hash结构存储数据对象集合,有序集合对数据对象创建索引</li>
<li>如果能将多维数据转为线性,则可以利用有序集合对数据进行list索引</li>
<li>两个分值一样的,则通过C函数memcmp比较</li>
</ol>
<h2 id="5-2-字典索引"><a href="#5-2-字典索引" class="headerlink" title="5.2 字典索引"></a>5.2 字典索引</h2><ol>
<li>ZRANGEBYLEX可以对值进行检索,包括或排除,可以利用在自动补全场景</li>
<li>可以再给值加上频率条件</li>
<li>考虑大小写条件时,可以按小写:频率:大写的方式存储值</li>
<li>使用组合索引,实际就是将多个字段信息组合后存储为有序集合</li>
<li>只要找到一种规则就可以合理利用ZRANGEBYLEX对数据进行查询</li>
</ol>
<h1 id="6-Replication"><a href="#6-Replication" class="headerlink" title="6. Replication"></a>6. Replication</h1><ol>
<li>主库发送将命令实时发送给从库</li>
<li>主从连接断开时会重连,并找回连接断开期间主库命令重新同步</li>
<li>如果找回断开期间部分的命令失败,则执行全部同步,具体由主库发送快照给从库,然后继续保持同步</li>
<li>从库复制异步进行,从库返回确认也是异步进行</li>
<li>如果从库落后主库,可以根据配置决定此时从库是否还可以使用旧的数据</li>
<li>主从复制的一个好处是可以避免主库持久化总是需要将数据写入磁盘,可以通过从库复制实时保存.然而需要注意的是,如果重启主库,主库数据集为空,从库同步复制主库时,从库数据也会被清空</li>
<li>建议在主从都开启持久化,或者如果不开启持久化则要避免重启机器后自动重启服务</li>
<li>每一个主库有一个replication id标识,对每个发送给从库的命令会有一个下标.如果从库断连后重连,则会告诉主库最后一个下标,并从该下标开始追赶执行命令同步主库</li>
<li>从新同步时,主库会开启一个存储进程生成RDB文件(写入磁盘),并缓存新接收的写命令.将RDB文件发送给从库,从库加载RDB文件到内存中,并接收主库缓存的命令然后继续同步</li>
<li>从库不会对key做expire操作,当主库key过期时执行del操作时发送到从库,从库执行</li>
<li>当访问从库已过期key时,因为主库的延迟操作,从库根据自身时钟做出判断报告该key不存在</li>
<li>主库执行Lua脚本时,时间被冻结,所以脚本必须同步到从库执行保证一致效果</li>
</ol>
<h1 id="7-Redis-Persistence"><a href="#7-Redis-Persistence" class="headerlink" title="7. Redis Persistence"></a>7. Redis Persistence</h1><h2 id="7-1-模式"><a href="#7-1-模式" class="headerlink" title="7.1 模式"></a>7.1 模式</h2><ol>
<li>RDB: 通过对某个时间点数据集存储为快照文件</li>
<li>AOF: 记录每一个写操作,通过重放方式初始化数据</li>
<li>可以在同一个实例中同时使用这两种模式,重启实例时,AOF模式用于从新初始化数据</li>
</ol>
<h2 id="7-2-RDB"><a href="#7-2-RDB" class="headerlink" title="7.2 RDB"></a>7.2 RDB</h2><ol>
<li>随心所欲对某个时间点的数据进行备份</li>
<li>适合用于灾难恢复</li>
<li>通过子进程完成备份,而父进程不用磁盘IO,不影响其他命令的进行</li>
<li>重启初始化数据更快</li>
<li>派生子进程,在数据集很大时会比较耗时.频繁备份对性能有一定损耗</li>
</ol>
<h2 id="7-3-AOF"><a href="#7-3-AOF" class="headerlink" title="7.3 AOF"></a>7.3 AOF</h2><ol>
<li>可以多种文件同步策略,每秒记录或每个写命令时记录,持续性更好</li>
<li>是一个只加文件,无需定位,容易修复</li>
<li>如果AOF文件太大时,redis会自动生成新的文件并切换到新的文件</li>
<li>如果不小心执行了FLUSHALL命令,只要还没有新的命令写入,停止实例.并将最后一个命令删除后重启redis就可以了</li>
</ol>
<h2 id="7-4-备份数据"><a href="#7-4-备份数据" class="headerlink" title="7.4 备份数据"></a>7.4 备份数据</h2><ol>
<li>redis会避免RDB和AOF的进程在同一时刻进行</li>
<li>建议设置定时任务生成每个小时的RDB文件放在一个文件夹和生成每天的RDB文件放在另一个文件夹</li>
<li>定时任务每次执行,清除比较老的RDB文件</li>
<li>每天转移RDB文件</li>
</ol>
<h1 id="8-Redis-Security"><a href="#8-Redis-Security" class="headerlink" title="8. Redis Security"></a>8. Redis Security</h1><ol>
<li>网络安全策略,将redis运行在虚拟化的linux实例避免直接暴露,外部无法通过防火墙连接redis,客户端通过环回地址与对应端口通信</li>
<li>安全模式: 从3.2.0版本开始,如果在配置上允许绑定所有端口,而且外部访问无需密码时会进入安全模式,只有通过环回地址的才能够正常访问,其他的客户端返回错误</li>
<li>认证功能: 密码应该设置足够长</li>
<li>数据加密: redis并不支持,不过可以再加一层SSL代理.redis推荐Spiped做对称加密</li>
<li>设置一些命令不可用</li>
<li>NoSQL注入: 注意从不可信赖来源获取可能为Lua脚本作为字符串的问题</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/redis-2/" data-id="cjscy3mzf000r3jzldbc5xho7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-redis-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/redis-1/" class="article-date">
  <time datetime="2018-06-30T06:41:04.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/redis-1/">Redis文档阅读笔记一</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-Pipelining"><a href="#1-Pipelining" class="headerlink" title="1. Pipelining"></a>1. Pipelining</h1><ol>
<li>Redis是一个TCPServer,使用CS模型</li>
<li>1次请求将命令集合发送,Redis执行命令后将结果队列化后,再写入返回</li>
<li>队列化执行结果需要使用内存,如果多次大批量操作需要注意内存的使用</li>
<li>使用Redis脚本能够处理更快处理批量命令.管道无法在脚本中使用,因为使用管道时在写入之前需要返回响应给客户端(需要注意:这里个人理解可能存在偏差).反之,管道可以使用脚本</li>
</ol>
<h1 id="2-Redis-Pub-Sub"><a href="#2-Redis-Pub-Sub" class="headerlink" title="2. Redis Pub/Sub"></a>2. Redis Pub/Sub</h1><ol>
<li>发布订阅模式: 发布者发布消息到Channel,订阅者订阅Channel接收消息</li>
<li>Redis客户端一旦为订阅模式,不能接收其他命令</li>
<li>redis-cli命令行客户端时进入订阅模式之后只能通过ctrl-c取消订阅,因为此时客户端阻塞等待接收订阅消息</li>
<li>发布订阅无关于key所在空间,db10发布的,db1订阅仍能接收</li>
<li>可用模式匹配发布多个channel 和订阅多个channel</li>
</ol>
<h1 id="3-Redis-Lua-scripting"><a href="#3-Redis-Lua-scripting" class="headerlink" title="3. Redis Lua scripting"></a>3. Redis Lua scripting</h1><ol>
<li>EVAL,EVALSHA命令执行Lua脚本</li>
<li>Lua 脚本可以使用redis.call 或redis.pcall执行redis命令</li>
<li>redis.call执行遇到错误时直接抛出Lua异常结果,redis.pcall则会把异常处理成Lua table返回</li>
<li>Lua调用redis命令时把数据转成redis对应数据类型,脚本执行结果返回给客户端时Lua的数据类型转成redis对应数据类型</li>
<li>使用Lua脚本时对于浮点数最好使用字符串替代</li>
<li>如果Lua返回数组中包含nil,则数据转换终止,最终只能返回nil之前的结果</li>
<li>redis.error_reply,redis.status_reply 在Lua脚本中是比较有用的按redis数据类型返回结果的方法</li>
<li>执行Lua脚本时,其他客户端的命令和脚本将无法执行</li>
<li>redis内部缓存机制会缓存脚本,使用EVALSHA,如果redis通过匹配SHA1文摘匹配到脚本,则执行脚本,否则返回错误信息通知使用EVAL代替</li>
<li>使用SCRIPT FLUSH或重启redis实例会刷新脚本缓存</li>
<li>脚本自身会被从库复制或写入AOF文件,而不是脚本的结果命令.不过从3.2版本开始,已经可选设置复制结果命令</li>
<li>脚本不允许设置全局变量</li>
</ol>
<h1 id="4-Debugging-Lua-scripts"><a href="#4-Debugging-Lua-scripts" class="headerlink" title="4. Debugging Lua scripts"></a>4. Debugging Lua scripts</h1><ol>
<li>Redis Lua debugger默认,每一个新的Debug session是一个forked session,这意味着当脚本在debug中时,不会阻塞redis server执行其他命令,同时也意味着debug结束后会回滚脚本执行的结果</li>
<li>官网有视频详解<a href="https://redis.io/topics/ldb" target="_blank" rel="noopener">https://redis.io/topics/ldb</a></li>
</ol>
<h1 id="5-Memory-optimization"><a href="#5-Memory-optimization" class="headerlink" title="5. Memory optimization"></a>5. Memory optimization</h1><ol>
<li>通过修改redis.conf调整每一种数据类型的最大数量和最大空间</li>
<li>RDB和AOF文件兼容32位和64位,之间可以互转</li>
<li>合理利用bit和byte操作</li>
<li>尽可能使用hash结构存储数据</li>
<li>每个hash最多存储100个field是cpu和内存之间的最佳妥协</li>
<li>redis根据配置文件maxmemory分配内存</li>
<li>被删除的key实际上并不会立刻释放内存,例如在同一页中存在其他的key未被删除,需要根据峰值内存使用量限定内存使用</li>
<li>redis底层内存分配器会尽可能重复利用被删除key的内存,所以也不用太担心被删除key没有及时释放的问题</li>
<li>如果不设置maxmemory,所有的内存将可能被吃光</li>
<li>当超过最大内存限制时,导致写入时out of memory error,但不会因此导致整个机器挂掉</li>
</ol>
<h1 id="6-Expires"><a href="#6-Expires" class="headerlink" title="6. Expires"></a>6. Expires</h1><ol>
<li>过期时间只针对key不针对值</li>
<li>过期时间可以通过persist命令清除</li>
<li>通过rename重命名key,原key的过期时间仍然有效,如果由别的key rename覆盖,则该key具有别的key的特性</li>
<li>如果设置的过期时间为过去时间,则key相当于del 而不是expired</li>
<li>消极检查: 当客户端获取该key时才检查该key是否过期</li>
<li>积极检查: redis 1秒内执行10个检查过期,每次随机选取20个key,发现过期的则清除,如果发现超过25%过期,则继续下一个检查</li>
<li>过期执行删除的命令会传递给从库和AOF文件同步执行.从库不会检查key过期,当切换为主库时才会去检查</li>
</ol>
<h1 id="7-Redis-as-an-LRU-Less-Recently-Used-cache"><a href="#7-Redis-as-an-LRU-Less-Recently-Used-cache" class="headerlink" title="7. Redis as an LRU (Less Recently Used) cache"></a>7. Redis as an LRU (Less Recently Used) cache</h1><h2 id="7-1-Redis达到最大内存限制时策略"><a href="#7-1-Redis达到最大内存限制时策略" class="headerlink" title="7.1 Redis达到最大内存限制时策略"></a>7.1 Redis达到最大内存限制时策略</h2><ol>
<li>noeviction: 直接抛出异常</li>
<li>allkeys-lru: 将最近不常用的key清除腾出空间</li>
<li>volatile-lru: 将带有过期时间的最近不常用的key清除腾出空间</li>
<li>allkeys-random: 随机将key清除腾出空间</li>
<li>volatile-random: 随机将带有过期时间的key清除腾出空间</li>
<li>volatile-ttl: 将较小剩余存活时间的key清除腾出空间</li>
<li>如果不确定使用哪种策略,allkeys-lru是一个较好选择</li>
<li>volatile-lru和volatile-random比较适用于只用单个实例,混用缓存和持久key</li>
</ol>
<h2 id="7-2-近似LRU算法"><a href="#7-2-近似LRU算法" class="headerlink" title="7.2 近似LRU算法"></a>7.2 近似LRU算法</h2><ol>
<li>redis使用的并不是实际的LRU算法,而是大致评估一定样本量中选取最符合的key</li>
<li>可以通过设置配置样本量参数maxmemory-samples调节精度</li>
</ol>
<h2 id="7-3-LFU-Least-Frequently-Used"><a href="#7-3-LFU-Least-Frequently-Used" class="headerlink" title="7.3 LFU (Least Frequently Used)"></a>7.3 LFU (Least Frequently Used)</h2><ol>
<li>4.0版本以后新增了新策略,根据命中的频率决定清除哪些key</li>
<li>lfu-log-factor和lfu-decay-time是两项主要调节参数</li>
</ol>
<h1 id="8-Redis-transactions"><a href="#8-Redis-transactions" class="headerlink" title="8. Redis transactions"></a>8. Redis transactions</h1><ol>
<li>事务中的所有命令会序列化并串行化执行,在事务过程中,其他客户端发起的请求不会被处理</li>
<li>所有命令要么全部被处理或不处理(这里的处理并不表示一定执行成功),保证了原子性</li>
<li>如果使用append-only file,在发生崩溃或强制关闭redis时有可能导致执行事务中部分命令.redis重启后会检测到直接退出.使用redis-check-aof tool修复</li>
<li>MULTI开启事务,命令存储到队列,命令EXEC执行事务所有命令</li>
<li>执行EXEC检测到命令错误时,会在EXEC直接返回错误信息,并丢弃所有命令</li>
<li>执行EXEC后,部分命令执行失败,对应的命令返回错误信息,其他命令执行成功</li>
<li>redis不支持回滚:因为官方认为不需要,语法上的错误,在命令队列化时就能检测到,而编码错误导致命令执行失败redis表示不背这个锅,redis追求更简单,更快</li>
<li>使用WATCH命令实现乐观锁,如果多个客户端对同一个key进行操作并存储时,被观察的key被改变后,其他客户端对该key的修改的事务则会失败,实现了对该key的原子操作</li>
<li>需要注意的一点,当WATCH某个key之后,key过期了,那EXEC就会正常执行</li>
<li>使用WATCH可以实现对有序集合操作的原子性</li>
<li>对事务的操作在脚本中也能实现,而且脚本可以更简单更快</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/redis-1/" data-id="cjscy3myu00093jzls00zakel" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mysql-6" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/mysql-6/" class="article-date">
  <time datetime="2018-06-30T06:21:03.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/《高性能MySQL》阅读笔记/">《高性能MySQL》阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/mysql-6/">《高性能MySQL》阅读笔记六</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-可扩展的Mysql"><a href="#1-可扩展的Mysql" class="headerlink" title="1. 可扩展的Mysql"></a>1. 可扩展的Mysql</h1><p>可扩展性: 通过增加资源提升容量的能力</p>
<h2 id="1-1-考虑负载"><a href="#1-1-考虑负载" class="headerlink" title="1.1 考虑负载"></a>1.1 考虑负载</h2><p>容量可以简单地认为是处理负载的能力,考虑负载可从以下几个角度</p>
<ol>
<li>数据量: 很多应用从不物理删除任何数据,应用所积累的数据量是可扩展的普遍挑战</li>
<li>用户量: 更多的用户意味着更多的事务,更多的复杂查询</li>
<li>用户活跃度</li>
<li>相关数据集的大小</li>
</ol>
<h2 id="1-2-规划可扩展性"><a href="#1-2-规划可扩展性" class="headerlink" title="1.2 规划可扩展性"></a>1.2 规划可扩展性</h2><ol>
<li>估算需要承担的负载到底有多少</li>
<li>大致正确地估计日程表</li>
<li>应用的功能完成多少</li>
<li>预期的最大负载是多少</li>
<li>如果依赖系统的每个部分分担负载,某个部分失效时会发生什么</li>
</ol>
<h2 id="1-3-向上扩展-垂直扩展"><a href="#1-3-向上扩展-垂直扩展" class="headerlink" title="1.3 向上扩展(垂直扩展)"></a>1.3 向上扩展(垂直扩展)</h2><ol>
<li>单台服务器增加各种高性能硬件</li>
<li>烧钱有效的方法</li>
<li>不应该无限制向上扩展</li>
</ol>
<h2 id="1-4-向外扩展"><a href="#1-4-向外扩展" class="headerlink" title="1.4 向外扩展"></a>1.4 向外扩展</h2><ol>
<li>策略: 复制,拆分,数据分片</li>
<li>按功能拆分: 常见做法,根据功能将应用部署在不同服务器,并使用专用的数据库服务器</li>
</ol>
<h3 id="1-4-1-数据分片"><a href="#1-4-1-数据分片" class="headerlink" title="1.4.1 数据分片"></a>1.4.1 数据分片</h3><p>数据分片是目前扩展大型MySQL最通用且最成功的方法</p>
<ol>
<li>应用设计初期考虑到,后期实现就比较容易,否则很难将应用从单一数据存储转换为分片架构</li>
<li>文中举例: 通过用户id来对文章和评论进行分片,而将用户的信息保留在单个节点上</li>
<li>数据库访问抽象层,降低应用和分片数据之间通信的复杂度</li>
<li>如非必要尽量不分片</li>
<li>数据分片最大的挑战就是查找和获取数据</li>
<li>类似于表分区,选择分区键和数据分片方式是关键,具体请细查</li>
</ol>
<h2 id="1-5-通过集群扩展"><a href="#1-5-通过集群扩展" class="headerlink" title="1.5 通过集群扩展"></a>1.5 通过集群扩展</h2><ol>
<li>可以使用集群或数据库分布式技术根据场景适当解决一些问题</li>
<li>书中提到技术: NDB Cluster, Clustrix等技术</li>
</ol>
<h2 id="1-6-向内扩展"><a href="#1-6-向内扩展" class="headerlink" title="1.6 向内扩展"></a>1.6 向内扩展</h2><ol>
<li>对不再需要的数据进行归档和清理</li>
<li>需要考虑对应用的影响</li>
<li>需要考虑数据逻辑的一致性,例如清理A表历史数据时需要考虑所有关联数据的处理</li>
<li>冷热数据分离</li>
</ol>
<h2 id="1-7-负载均衡"><a href="#1-7-负载均衡" class="headerlink" title="1.7 负载均衡"></a>1.7 负载均衡</h2><h3 id="1-7-1-目的"><a href="#1-7-1-目的" class="headerlink" title="1.7.1 目的"></a>1.7.1 目的</h3><ol>
<li>可扩展性: 如读写分离时从备库读数据</li>
<li>高效性: 把更多工作分配给更好的机器</li>
<li>可用性: 使用时刻保持可用的服务器</li>
<li>透明性: 客户端无需知道服务器</li>
<li>一致性: 如果应用是有状态的,负载均衡器就应该将相关的查询指向同一个服务器</li>
</ol>
<h3 id="1-7-2-直接连接"><a href="#1-7-2-直接连接" class="headerlink" title="1.7.2 直接连接"></a>1.7.2 直接连接</h3><h4 id="1-7-2-1-复制上的读写分离"><a href="#1-7-2-1-复制上的读写分离" class="headerlink" title="1.7.2.1 复制上的读写分离"></a>1.7.2.1 复制上的读写分离</h4><ol>
<li>基于查询分离: 将不能容忍脏数据的查询分配到主库,其他分配到备库</li>
<li>基于脏数据分离: 让应用检查复制延迟,许多报表类应用使用这个策略</li>
<li>基于会话分离: 可以在会话层做一个标记,如果用户修改了数据,则一段时间内总是指向主库</li>
<li>基于版本分离: 给用户的操作增加版本号,检查版本号决定从主库还是备库读取数据</li>
</ol>
<h4 id="1-7-2-3-修改DNS名"><a href="#1-7-2-3-修改DNS名" class="headerlink" title="1.7.2.3 修改DNS名"></a>1.7.2.3 修改DNS名</h4><ol>
<li>通过变更DNS名指定的服务器实现</li>
<li>缺点很多,不建议</li>
</ol>
<h4 id="1-7-2-4-转移IP地址"><a href="#1-7-2-4-转移IP地址" class="headerlink" title="1.7.2.4 转移IP地址"></a>1.7.2.4 转移IP地址</h4><ol>
<li>在服务器之间转移虚拟地址</li>
<li>给服务器分配固定的ip地址,为每个逻辑上的服务使用一个虚拟ip地址</li>
</ol>
<h3 id="1-7-3-引入中间件"><a href="#1-7-3-引入中间件" class="headerlink" title="1.7.3 引入中间件"></a>1.7.3 引入中间件</h3><ol>
<li>负载均衡器,如HAproxy</li>
<li>负载均衡算法: 随机, 轮询,最少连接数,最快响应,哈希,权重</li>
<li>服务器池中增加或移除服务器: 在配置连接池中的服务器时,要保证有足够多未使用的容量</li>
</ol>
<h1 id="2-高可用性"><a href="#2-高可用性" class="headerlink" title="2. 高可用性"></a>2. 高可用性</h1><ol>
<li>高可用性意味着更少的宕机时间<h2 id="2-1-宕机原因"><a href="#2-1-宕机原因" class="headerlink" title="2.1 宕机原因"></a>2.1 宕机原因</h2></li>
<li>磁盘空间不足</li>
<li>糟糕的sql或者服务器bug引起</li>
<li>糟糕的表和索引设计</li>
<li>复制问题通常由于主备数据不一致导致</li>
</ol>
<h2 id="2-2-高可用性实现"><a href="#2-2-高可用性实现" class="headerlink" title="2.2 高可用性实现"></a>2.2 高可用性实现</h2><ol>
<li>衡量指标: 平均失效时间(MTBF), 平均恢复时间(MTTR)</li>
<li>避免问题: 适当的配置,监控和规范</li>
<li>保证在宕机时能快速恢复,系统制造冗余,具备故障转移能力</li>
</ol>
<h3 id="2-2-1-避免单点失效"><a href="#2-2-1-避免单点失效" class="headerlink" title="2.2.1 避免单点失效"></a>2.2.1 避免单点失效</h3><ol>
<li>通过增加冗余避免</li>
<li>共享存储或磁盘复制,如果服务器挂了,备用服务器可以挂载相同的文件系统执行需要的恢复操作</li>
<li>MySQL同步复制</li>
</ol>
<h3 id="2-2-2-故障转移和故障恢复"><a href="#2-2-2-故障转移和故障恢复" class="headerlink" title="2.2.2 故障转移和故障恢复"></a>2.2.2 故障转移和故障恢复</h3><ol>
<li>提升备库或切换角色</li>
<li>虚拟IP地址或IP接管: 当MySQL实例失效时可以将IP地址转移到另一台MySQL服务器上</li>
<li>使用中间件解决方案</li>
</ol>
<h1 id="3-备份与恢复"><a href="#3-备份与恢复" class="headerlink" title="3. 备份与恢复"></a>3. 备份与恢复</h1><h2 id="3-1-设计MySQL备份方案考虑点"><a href="#3-1-设计MySQL备份方案考虑点" class="headerlink" title="3.1 设计MySQL备份方案考虑点"></a>3.1 设计MySQL备份方案考虑点</h2><ol>
<li>在线备份还是离线备份</li>
<li>逻辑备份还是物理备份</li>
<li>非显著数据: 如二进制日志和InnoDB事务日志</li>
<li>代码: 存储过程,触发器</li>
<li>服务器配置和复制配置</li>
<li>外部配置,管理脚本</li>
<li>增量备份和差异备份</li>
<li>存储引擎和数据一致性</li>
</ol>
<h2 id="3-2-备份数据方式"><a href="#3-2-备份数据方式" class="headerlink" title="3.2 备份数据方式"></a>3.2 备份数据方式</h2><ol>
<li>文件系统中或SAN快照中直接复制数据文件</li>
<li>Percona XtraBackup 做热备份</li>
</ol>
<h2 id="3-3-InnoDB崩溃恢复"><a href="#3-3-InnoDB崩溃恢复" class="headerlink" title="3.3 InnoDB崩溃恢复"></a>3.3 InnoDB崩溃恢复</h2><ol>
<li>二级索引损坏: 使用OPTIMIZE TABLE修复损坏的二级索引,此外可以通过构建一个新表重建受影响的索引</li>
<li>聚簇索引损坏: innodb_force_recovery导出表</li>
<li>损坏系统结构: 系统结构包括事务日志等,可能需要做整个数据库的导出和还原,因为InnoDB内部绝大部分的工作可能受影响</li>
</ol>
<h1 id="4-MySQL用户工具"><a href="#4-MySQL用户工具" class="headerlink" title="4. MySQL用户工具"></a>4. MySQL用户工具</h1><p>工欲善其事,必先利其器</p>
<h2 id="4-1-接口工具"><a href="#4-1-接口工具" class="headerlink" title="4.1 接口工具"></a>4.1 接口工具</h2><ol>
<li>MySQL Workbench: 一站式的工具</li>
<li>SQLyog: 可视化工具之一</li>
</ol>
<h2 id="4-2-命令行工具集"><a href="#4-2-命令行工具集" class="headerlink" title="4.2 命令行工具集"></a>4.2 命令行工具集</h2><ol>
<li>Percona Toolkit</li>
<li>MySQL Workbench 工具集</li>
</ol>
<h2 id="4-3-SQL实用集"><a href="#4-3-SQL实用集" class="headerlink" title="4.3 SQL实用集"></a>4.3 SQL实用集</h2><ol>
<li>common_schema</li>
<li>MySQL Forge</li>
</ol>
<h2 id="4-4-监测工具"><a href="#4-4-监测工具" class="headerlink" title="4.4 监测工具"></a>4.4 监测工具</h2><ol>
<li>Nagios</li>
<li>Zabbix: 同时支持监控和指标收集的完整系统</li>
<li>Zenoss: Python写的</li>
<li>Hyperic HQ: 基于Java</li>
</ol>
<h2 id="4-5-Innotop命令行监控"><a href="#4-5-Innotop命令行监控" class="headerlink" title="4.5 Innotop命令行监控"></a>4.5 Innotop命令行监控</h2><p>主要包括以下功能</p>
<ol>
<li>事务列表</li>
<li>当前运行的查询</li>
<li>当前锁和锁等待列表</li>
<li>服务器状态和变量汇总信息</li>
<li>InnoDB内部信息</li>
<li>复制监控</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/mysql-6/" data-id="cjscy3myq00063jzlz6ln2xr6" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mysql-5" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/30/mysql-5/" class="article-date">
  <time datetime="2018-06-30T06:15:53.000Z" itemprop="datePublished">2018-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/《高性能MySQL》阅读笔记/">《高性能MySQL》阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/30/mysql-5/">《高性能MySQL》阅读笔记五</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-优化服务器设置"><a href="#1-优化服务器设置" class="headerlink" title="1. 优化服务器设置"></a>1. 优化服务器设置</h1><ol>
<li>MySQL有大量的可以修改的参数,但不应该随便修改.应该将更多时间花在schema的优化,索引,查询设计上</li>
<li>配置文件路径: 通常在/etc/my.cnf</li>
<li>不建议动态修改变量,因为可能导致意外的副作用</li>
<li>通过基准测试迭代优化</li>
<li>具体配置项设置请参照官网手册,这里只提及部分</li>
</ol>
<h2 id="1-1-配置内存使用"><a href="#1-1-配置内存使用" class="headerlink" title="1.1 配置内存使用"></a>1.1 配置内存使用</h2><ol>
<li>确定可使用内存上限</li>
<li>每个连接使用多少内存,如排序缓冲和临时表</li>
<li>确定操作系统内存使用量</li>
<li>把剩下的分配给缓存,如InnoDB缓存池</li>
</ol>
<h2 id="1-2-配置MySQL的I-O行为"><a href="#1-2-配置MySQL的I-O行为" class="headerlink" title="1.2 配置MySQL的I/O行为"></a>1.2 配置MySQL的I/O行为</h2><ol>
<li>有些配置项影响如何同步数据到磁盘及如何恢复操作,这对性能影响很大,而且表现了性能和数据安全之间的平衡<h3 id="1-2-1-InnoDB-I-O配置"><a href="#1-2-1-InnoDB-I-O配置" class="headerlink" title="1.2.1 InnoDB I/O配置"></a>1.2.1 InnoDB I/O配置</h3></li>
<li>重要配置: InnoDB日志文件大小,InnoDB怎样刷新日志缓冲,InnoDB怎样执行I/O</li>
<li>InnoDB使用日志减少提交事务时开销,不用每个事务提交时把缓冲池的脏块刷到磁盘中</li>
<li>事务日志可以把随机IO变成顺序IO,同时如果发生断电,InnoDB可以重放日志恢复已经提交的事务</li>
<li>sync_binlog选项控制MySQL怎么刷新二进制日志到磁盘</li>
<li>把二进制日志放到一个带有电池保护的写缓存的RAID卷可以极大的提升性能</li>
</ol>
<h3 id="1-2-2-MyISAM的I-O配置"><a href="#1-2-2-MyISAM的I-O配置" class="headerlink" title="1.2.2 MyISAM的I/O配置"></a>1.2.2 MyISAM的I/O配置</h3><ol>
<li>因为MyISAM表每次写入都会将索引变更刷新到磁盘</li>
<li>批量操作时,通过设置delay_key_write可以延迟索引写入,可以提升性能</li>
<li>配置MyISAM怎样尝试从损坏中恢复</li>
</ol>
<h2 id="1-3-配置MySQL并发"><a href="#1-3-配置MySQL并发" class="headerlink" title="1.3 配置MySQL并发"></a>1.3 配置MySQL并发</h2><h3 id="1-3-1-InnoDB并发配置"><a href="#1-3-1-InnoDB并发配置" class="headerlink" title="1.3.1 InnoDB并发配置"></a>1.3.1 InnoDB并发配置</h3><ol>
<li>如果在InnoDB并发方面有问题,解决方案通常是升级服务器</li>
<li>innodb_thread_concurrency: 限制一次性可以有多少线程进入内核(根据实践取合适值)</li>
<li>innodb_thread_sleep_delay: 线程第一次进入内核失败等的时间,如果还不能进入则放入等待线程队列</li>
<li>innodb_commit_concurrency: 控制有多少线程可以在同一时间提交</li>
<li>使用线程池限制并发: MariaDB已经实现</li>
</ol>
<h3 id="1-3-2-MyISAM并发配置"><a href="#1-3-2-MyISAM并发配置" class="headerlink" title="1.3.2 MyISAM并发配置"></a>1.3.2 MyISAM并发配置</h3><ol>
<li>concurrency_insert: 配置MyISAM打开并发插入</li>
</ol>
<h2 id="1-4-其他"><a href="#1-4-其他" class="headerlink" title="1.4 其他"></a>1.4 其他</h2><ol>
<li>基于工作负载的配置: 利用工具分析并调整配置</li>
<li>max_connections: 保证服务器不会因应用程序激增的连接而不堪重负</li>
<li>安全和稳定的设置: 感兴趣者请自行google</li>
<li>高级InnoDB设置: 感兴趣者请自行google</li>
<li>InnoDB两个重要配置: innodb_buffer_pool_size和innodb_log_file_size</li>
</ol>
<h1 id="2-复制"><a href="#2-复制" class="headerlink" title="2. 复制"></a>2. 复制</h1><p>MySQL内建的复制功能是构建基于MySQL的大规模,高性能应用的基础.同时也是高可用性,可扩展性,灾难恢复,备份及数据仓库等工作的基础</p>
<h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h2><ol>
<li>解决问题: 让一台服务器的数据与其他服务器保持同步.主库可以同步到多台备库,备库本身也可以配置为另一台服务器的主库</li>
<li>复制原理: 通过在主库上记录二进制日志,在备库重放日志的方式实现异步的数据复制</li>
<li>复制方式: 基于行的复制和基于语句的复制</li>
<li>向后兼容: 新版本只能作为老版本的备库,反之不行</li>
</ol>
<h2 id="2-2-用途"><a href="#2-2-用途" class="headerlink" title="2.2 用途"></a>2.2 用途</h2><ol>
<li>数据分布: 在不同地理位置分布数据备份,可以随意停止或开始复制.基于行比基于语句带宽压力更大</li>
<li>负载均衡: 将读操作分布到多个服务器上</li>
<li>备份: 复制是备份的一项有意义的技术补充</li>
<li>高可用性和故障切换: 避免单点失败</li>
<li>MySQL升级测试: 一种普遍做法是使用一个更高版本的MySQL作为备库保证实例升级前查询能够在备库按照预期执行</li>
</ol>
<h2 id="2-3-过程"><a href="#2-3-过程" class="headerlink" title="2.3 过程"></a>2.3 过程</h2><ol>
<li>主库把数据更改记录到二进制日志(Binary Log)</li>
<li>备库将主库上的日志复制到自己的中继日志(Relay Log)</li>
<li>备库读取中继日志中的事件,将其重放到备库数据上</li>
<li>局限: 主库上并发运行的查询在备库只能串行化执行,因为只有一个sql线程重放中继日志事件,这是很多工作负载的性能瓶颈</li>
</ol>
<h2 id="2-4-复制配置"><a href="#2-4-复制配置" class="headerlink" title="2.4 复制配置"></a>2.4 复制配置</h2><ol>
<li>在每台服务器上创建复制账号: 需要REPLICATION SLAVE权限</li>
<li>配置主库和备库: 每个服务器的ID需要唯一不能冲突</li>
<li>通知备库连接到主库并从主库复制数据</li>
<li>CHANGE MASTER TO: 指定备库连接的主库设置</li>
<li>SHOW SLAVE STATUS: 检查复制是否正确执行</li>
<li>START SLAVE: 开始复制</li>
<li>SHOW PROCESSLIST: 查看复制线程,IO线程(发送或获取日志),SQL线程(重放日志)</li>
<li>推荐配置: 开启sync_binlog</li>
</ol>
<h2 id="2-5-从另一个服务器开始复制"><a href="#2-5-从另一个服务器开始复制" class="headerlink" title="2.5 从另一个服务器开始复制"></a>2.5 从另一个服务器开始复制</h2><p>问题: 主库已经运行一段时间,用一台新安装的备库与之同步<br>保持同步条件:</p>
<ol>
<li>某个时间点的主库的数据快照</li>
<li>主库当前的二进制日志文件,和获得数据快照时在该二进制日志文件中的偏移量.通过这两个可以确定二进制日志的位置</li>
<li>从快照时间到现在的二进制日志</li>
</ol>
<p>克隆备库方法:</p>
<ol>
<li>冷备份: 关闭主库,复制数据.主库重启后会使用新的二进制文件,在备库指向这个文件的起始处</li>
<li>热备份:如果只有MyISAM,可以通过mysqlhotcopy或rsync来复制数据</li>
<li>如果只包含InnoDB: 可以使用mysqldump转储主库数据并加载到备库,然后设置相应的二进制日志坐标</li>
<li>使用快照或备份: 使用主库的快照或者备份初始化备库,然后指定二进制日志坐标</li>
<li>使用Percona Xtrabackup: 备份时不阻塞服务器操作,可以在不影响主库情况下设置备库</li>
<li>使用另外的备库: 实质就是把另外的备库当成主库进行数据克隆</li>
</ol>
<h2 id="2-6-复制的原理"><a href="#2-6-复制的原理" class="headerlink" title="2.6 复制的原理"></a>2.6 复制的原理</h2><h3 id="2-6-1-基于语句的复制"><a href="#2-6-1-基于语句的复制" class="headerlink" title="2.6.1 基于语句的复制"></a>2.6.1 基于语句的复制</h3><ol>
<li>主库会记录那些造成数据更改的查询</li>
<li>MySQL5.0之前只支持基于语句的复制</li>
<li>对于函数,存储过程和触发器在基于语句的复制模式可能存在问题</li>
<li>更新必须是串行,需要更多的锁</li>
</ol>
<h3 id="2-6-2-基于行的复制"><a href="#2-6-2-基于行的复制" class="headerlink" title="2.6.2 基于行的复制"></a>2.6.2 基于行的复制</h3><ol>
<li>将实际的数据记录在二进制日志</li>
<li>能够更高效复制数据</li>
<li>基于行的复制事件格式,对人不可读,可以使用mysqlbinlog</li>
<li>很难进行时间点恢复</li>
<li>有些操作,如全表更新(update)复制开销会很大</li>
</ol>
<h2 id="2-7-复制拓扑"><a href="#2-7-复制拓扑" class="headerlink" title="2.7 复制拓扑"></a>2.7 复制拓扑</h2><h3 id="2-7-1-基本原则"><a href="#2-7-1-基本原则" class="headerlink" title="2.7.1 基本原则"></a>2.7.1 基本原则</h3><ol>
<li>一个MySQL备库实例只能有一个主库</li>
<li>每个备库必须有一个唯一的服务器id</li>
<li>一个主库可以有多个备库</li>
<li>如果打开log_slave_update一个备库可以把其主库上的数据变化传播到其他备库</li>
</ol>
<h3 id="2-7-2-一主多备"><a href="#2-7-2-一主多备" class="headerlink" title="2.7.2 一主多备"></a>2.7.2 一主多备</h3><ol>
<li>适用于少量写和大量读,可以把读分摊到多个备库上</li>
<li>当作待用的主库</li>
<li>放到远程数据中心,用作灾难恢复</li>
<li>作为备份,培训,开发或测试服务器</li>
</ol>
<h3 id="2-7-3-双主复制"><a href="#2-7-3-双主复制" class="headerlink" title="2.7.3 双主复制"></a>2.7.3 双主复制</h3><ol>
<li>个数据库互为主库和备库</li>
<li>容易造成数据不同步</li>
<li>通常并不建议使用这种模式</li>
</ol>
<h3 id="2-7-4-主动被动的双主模式"><a href="#2-7-4-主动被动的双主模式" class="headerlink" title="2.7.4 主动被动的双主模式"></a>2.7.4 主动被动的双主模式</h3><ol>
<li>类似双主复制,把其中一台配置为只读</li>
<li>类似于创建一个热备份</li>
<li>可以用作执行读操作,备份,离线维护及升级</li>
</ol>
<h3 id="2-7-5-有备库的双主模式"><a href="#2-7-5-有备库的双主模式" class="headerlink" title="2.7.5 有备库的双主模式"></a>2.7.5 有备库的双主模式</h3><ol>
<li>双主模式下,各自有备库</li>
</ol>
<h3 id="2-7-6-主库-分发主库和备库"><a href="#2-7-6-主库-分发主库和备库" class="headerlink" title="2.7.6 主库,分发主库和备库"></a>2.7.6 主库,分发主库和备库</h3><ol>
<li>问题: 备库足够多时会对主库造成很大的负载</li>
<li>方案: 将其中部分备库当成主库,分发给更多的备库</li>
<li>通过分发主库,可以对二进制日志事件执行过滤和重写规则</li>
</ol>
<h2 id="2-8-复制管理和维护"><a href="#2-8-复制管理和维护" class="headerlink" title="2.8 复制管理和维护"></a>2.8 复制管理和维护</h2><ol>
<li>监控复制: SHOW MASTER STATUS查看主库状态, SHOW BINLOG EVENTS查看复制事件</li>
<li>测量备库延迟: 可以使用Percona Toolkit里的pt-hearbeat</li>
<li>确定主备是否一致</li>
<li>备库换主库: 难点在于获取新主库合适的二进制日志位置</li>
<li>备库提升为主库分为计划内提升和计划外提升<h3 id="2-8-1-计划内提升"><a href="#2-8-1-计划内提升" class="headerlink" title="2.8.1 计划内提升"></a>2.8.1 计划内提升</h3></li>
<li>停止向老的主库写入</li>
<li>备库赶上主库</li>
<li>备库设置为主库</li>
<li>将备库和写操作指向新主库,然后开启主库的写入</li>
</ol>
<h3 id="2-8-2-计划外提升"><a href="#2-8-2-计划外提升" class="headerlink" title="2.8.2 计划外提升"></a>2.8.2 计划外提升</h3><p>当主库崩溃时,需要提升一台备库替代</p>
<ol>
<li>确定最新的备库</li>
<li>让所有备库执行完从崩溃前主库获得的中继日志,如果未完成则更换主库,会丢失原先的日志事件</li>
<li>重新完成主备的配置</li>
</ol>
<h2 id="2-9-复制的问题和解决方案"><a href="#2-9-复制的问题和解决方案" class="headerlink" title="2.9 复制的问题和解决方案"></a>2.9 复制的问题和解决方案</h2><h3 id="2-9-1-数据损坏或丢失"><a href="#2-9-1-数据损坏或丢失" class="headerlink" title="2.9.1 数据损坏或丢失"></a>2.9.1 数据损坏或丢失</h3><ol>
<li>主库意外关闭: 主库开启sync_binlog避免事件丢失,使用Percona Toolkit中的pt-table-checksum检查主备一致性</li>
<li>备库意外关闭: 重启后观察MySQL错误日志,想方法获取备库指向主库的日志偏移量</li>
<li>主库上的二进制日志损坏: 跳过所有损坏的事件,手动找到一个完好的事件开始</li>
<li>备库上的中继日志损坏: MySQL5.5后能在崩溃后自动重新获取中继日志</li>
<li>二进制日志于InnoDB事务日志不同步: 除非备库中继日志有保存,否则自求多福</li>
</ol>
<h3 id="2-9-2-其他"><a href="#2-9-2-其他" class="headerlink" title="2.9.2 其他"></a>2.9.2 其他</h3><ol>
<li>如果使用myisam,在关闭Mysql前需要确保已经运行了stop slave,否则在服务器关闭时会kill所有正在运行的查询. </li>
<li>如果是事务型,失败的更新会在主库上回滚而且不会记录到二进制日志</li>
<li>避免混用事务和非事务: 如果备库发生死锁而主库没有,事务型会回滚而非事务型则不会造成不同步</li>
<li>主库和备库使用不同存储引擎容易导致问题</li>
<li>不唯一和未定义备库服务器id</li>
<li>避免在主库上创建备库上没有的表,因为复制可能中断</li>
<li>基于语句复制时,主库上没有安全使用临时表的方法.丢失临时表: 备库崩溃时,任何复制线程拥有的临时表都会丢失,重启备库后所有依赖临时表的语句都会失败</li>
<li>InnoDB加锁读引起的锁争用: 将大命令拆成小命令可以有效减少锁竞争</li>
<li>过大的复制延迟: 定位执行慢的语句,改善机器配置</li>
<li>其他: 查看官网手册</li>
</ol>
<h2 id="2-10-复制高级特性"><a href="#2-10-复制高级特性" class="headerlink" title="2.10 复制高级特性"></a>2.10 复制高级特性</h2><ol>
<li>半同步复制: 当提交事务,客户端收到查询结束反馈前必须保证二进制日志已经传输到至少一台备库上,主库将事务提交到磁盘上之后会增加一些延迟</li>
<li>复制心跳: 保证备库一直与主库相联系,如果出现断开的网络连接,备库会注意到丢失的心跳数据</li>
</ol>
<h2 id="2-11-其他复制技术"><a href="#2-11-其他复制技术" class="headerlink" title="2.11 其他复制技术"></a>2.11 其他复制技术</h2><ol>
<li>Percona XtraDB Cluster的同步复制</li>
<li>Tungsten</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://whales2018.github.io/2018/06/30/mysql-5/" data-id="cjscy3mzd000p3jzl6ai4uzuk" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx文档笔记/">Nginx文档笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python源码学习/">Python源码学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis文档阅读笔记/">Redis文档阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《HTTP权威指南》阅读笔记/">《HTTP权威指南》阅读笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《现代操作系统》阅读笔记一/">《现代操作系统》阅读笔记一</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《高性能MySQL》阅读笔记/">《高性能MySQL》阅读笔记</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/17/amqp/">Python amqp源码学习</a>
          </li>
        
          <li>
            <a href="/2018/06/30/redis-2/">Redis文档阅读笔记二</a>
          </li>
        
          <li>
            <a href="/2018/06/30/redis-1/">Redis文档阅读笔记一</a>
          </li>
        
          <li>
            <a href="/2018/06/30/mysql-6/">《高性能MySQL》阅读笔记六</a>
          </li>
        
          <li>
            <a href="/2018/06/30/mysql-5/">《高性能MySQL》阅读笔记五</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Whales<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>